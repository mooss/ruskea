#+TITLE: Distanciel modèles de Markov cachés
#+AUTHOR: Félix Jamet
#+OPTIONS: toc:2 tags:nil
#+LANGUAGE: fr
#+PROPERTY: header-args:ipython :session markexec :results silent :tangle markov.py :eval no-export :noweb yes

* Consignes

L’expérimentation présentée dans l’article est (à mon avis) passionnante. Et il serait intéressant de la reproduire sur une autre langue, par exemple la langue française. Pour cela vous devrez:

 - Trouver un corpus en langue française, de taille raisonnable (prendre en référence ce qui est proposé dans l’article)
 - Nettoyer ce corpus pour ne garder que les 26 lettres de l’alphabet et les espaces
 - Utiliser un EM/Baum Welch déjà implémenté (par exemple dans les bibliothèques des langages de programmation) ou utilisez le pseudo-code fourni dans l’algorithme pour réimplémenter votre Baum Welch, pour apprendre les paramètres de votre HMM.
 - Dessinez le HMM (si vous avez utilisé une bibliothèque) et analysez les résultats : à deux classes a-t-on bien les voyelles et les consonnes?

Si vous êtes plus de 2 à faire le choix 4, il est demandé de regarder d’autres langues, en particulier l’Espagnol et l’Allemand. On peut prendre comme base : n étudiants : n-1 langues.

* Quelques définitions
 - États :: ce que l'on cherche à prédir.
 - Observations :: informations supplémentaires que l'on va utiliser afin de prédire les états.

* Notations

#+CAPTION: Notation des modèles de Markov
#+NAME: tbl.notations
| symbole                                                                  | signification                        |
|--------------------------------------------------------------------------+--------------------------------------|
| $A$                                                                      | matrice des transitions              |
| $B$                                                                      | matrice des observations             |
| $\pi$                                                                    | distribution initiale des états      |
|--------------------------------------------------------------------------+--------------------------------------|
| $N$                                                                      | nombre d'états dans le modèle        |
| $Q = \{q_0, q_1, \dots, \q_{N-1}\}$                                      | ensemble des états                   |
|--------------------------------------------------------------------------+--------------------------------------|
| $M$                                                                      | nombres de symboles d'observation    |
| $V = \{0, 1, \dots, M-1\}$                                               | ensemble des observations possibles  |
| $T$                                                                      | longueur de la chaine d'observations |
| $\mathcal{O} = (\mathcal{O}_0, \mathcal{O}_1, \dots, \mathcal{O}_{T-1})$ | chaine d'observations                |

La table [[tbl.notations]] est séparée en trois parties.
La première rassemble ce qui définit un modèle de Markov, la deuxième est constituée de caractéristiques calculées et la dernière partie concerne les observations.

La matrice des transitions est notée $A = \{a_{i,j}\}$, avec
$a_{i,j} = P(\text{ état } q_j \text{ au temps } t+1 | \text{ état } q_i \text{ au temps } t)$.
Ainsi, si on envisage de manipuler la matrice $A$ comme un tableau de tableaux, on a $A[i][j] = a_{i,j}$


$A_{i,j}$ correspond à la probabilité d'être dans l'état $q_j$ sachant qu'on était avant dans l'état $q_i$.
Autrement dit, la probabilité de passer dans l'état $q_j$ si l'on est dans l'état $q_i$.
On remarque que les probabilités des transitions sont indépendantes du temps $t$.

La matrice des observations est notée $B = \{b_j(k)\}$, avec
$$b_j(k) = P(\text{observation } k \text{ au temps } t | \text{ état } q_j \text{ au temps } t)$$
$b_j(k)$ est donc la probabilité d'observer $k$ en étant dans l'état $q_j$. Bien que surprenante, la notation $b_j(k)$ semble être standard dans le domaine des modèles de Markov.

$\pi$ est la distribution initiale des états, c'est à dire la probabilité de démarer dans chacun des état. Il s'agit donc là encore d'une matrice stochastique.

Un modèle de Markov caché (MMC) est défini par $A$, $B$ et $\pi$, et se note typiquement $$\lambda = (A, B, \pi)$$

* Problèmes pour lesquels les MMC sont utiles
Il existe trois problèmes particuliers qui peuvent être résolus à l'aide des modèles de Markov cachés.

** Problème 1
Étant donné un MMC et une chaine d'observations, trouver la probabilité de cette chaine selon ce modèle. Autrement dit, étant donné le MMC $\lambda = (A, B, \pi)$ et la chaine d'observation 
$\mathcal{O} = (\mathcal{O}_0, \mathcal{O}_1, \dots, \mathcal{O}_{T-1})$
, trouver $P(\mathcal{O} | \lambda )$.

Cette probabilité correspond à la somme des probabilités d'observer $\mathcal{O}$ sur tous les arrangements avec répétition de longueur $T$ des états de $\lambda$.
Étant donné que cette méthode revient à faire une somme sur $N^T$ éléments, on développe l'intuition qu'elle n'est pas viable.

** Problème 2
Étant donné un MMC et une chaine d'observation, trouver l'enchainement d'états optimal correspondant.

Les enchainements optimaux d'états trouvés par la programmation dynamique et par les modèles de Markov cachés sont susceptibles de différer. En effet, la programmation dynamique permettra de trouver l'enchainement d'états ayant la plus haute probabilité, tandis que les MMC vont trouver l'enchainement dont les états ont la plus grande probabilité d'être individuelement corrects.
Autrement dit, les MMC vont permettre de maximiser le nombre d'états corrects.

** Problème 3
Étant donné une chaine d'observation, un nombre d'états et un nombre de symboles, trouver le MMC maximisant la probabilité de cette chaine d'observation, autrement dit, entrainer un HMM pour le faire correspondre aux observations.

* Réimplémentation de Baum-Welch
:PROPERTIES:
:header-args:ipython: :session markexec :results silent :tangle markov.py
:END:
** Modèles de Markov
 
#+BEGIN_SRC ipython :results silent
  import math
  import random
  from numpy import zeros, full, array
  from copy import deepcopy

  def stochastic_variation(mat, epsilon):
      """Slightly changes the values of a matrix while making sure that the sum of the rows are kept the same.

      Parameters
      ----------
      mat : np.matrix
          Matrix to change.

      epsilon : float
          Maximal variation.
      """
      random.seed()
      for row in mat:
          delta = 0
          for i in range(0, len(row)):
              # if delta > epsilon / 2:
              #     nextvariation = random.uniform(-epsilon, 0)
              # elif delta < -epsilon / 2:
              #     nextvariation = random.uniform(0, epsilon)
              # else:
              #     nextvariation = random.uniform(-epsilon, epsilon)
              if random.uniform(0, 1) >= .5:
                  row[i] += random.uniform(*epsilon) #nextvariation
              else:
                  row[i] -= random.uniform(*epsilon)

              if row[i] < 0:
                  row[i] = -row[i]
                  # delta += nextvariation

          factor = 1/sum(row)
          for i in range(0, len(row)):
              row[i] *= factor
          #     nextvalue = random.gauss(row[i], epsilon)
          #     delta += nextvalue - row[i]
          #     row[i] = nextvalue
          # meandelta = delta/len(row)
          # for i in range(0, len(row)):
          #     row[i] -= meandelta


  def prob_matrix(M, p_range):
      try:
          for i in range(M.shape[0]):
              for j in range(M.shape[1]):
                  if random.uniform(0, 1) >= .5:
                      M[i][j] += random.uniform(p_range[0], p_range[1])
                  else:
                      M[i][j] -= random.uniform(p_range[0], p_range[1])
          for i in range(M.shape[0]):
              factor = M[i].sum()
              for j in range(M.shape[1]):
                  M[i][j] *= 1/factor
      except:
          for j in range(M.shape[0]):
              if random.uniform(0, 1) >= .5:
                  M[j] += random.uniform(p_range[0], p_range[1])
              else:
                  M[j] -= random.uniform(p_range[0], p_range[1])
          factor = M.sum()
          for j in range(M.shape[0]):
              M[j] *= 1/factor
      return M


  class markovmodel(object):
      def fromscratch(N, M):
          """Create a Markov model from scratch with the following matrices dimensions:
           - A is NxN
           - B is NxM
           - PI is 1xN

          Parameters
          ----------
          N : int

          M : int

          Returns
          -------
          out : The corresponding Markov model
          """
          inverseN = 1 / N
          inverseM = 1 / M

          transition = full((N, N), inverseN)
          observation = full((N, M), inverseM)
          initial = full((1, N), inverseN)

          # prob_matrix(transition, (0.001, 0.005))
          # prob_matrix(observation, (0.02, 0.025))
          stochastic_variation(transition, (0.000, 0.005))
          stochastic_variation(observation, (0.02, 0.025))
          stochastic_variation(initial, (0.001, 0.005))

          return markovmodel(transition, observation, initial)

      def __init__(self,
                   transition_matrix,
                   observation_matrix,
                   initial_state_distribution,
                   rel_tol=1e-9):
          """Create a Markov model.

          Parameters
          ----------
          transition_matrix : np.matrix
              NxN matrix containing the state transitions probabilities.

          observation_matrix : np.matrix
              NxM matrix containing the observation probabilities.

          initial_state_distribution : np.matrix
              1xN matrix containing the initial state distribution
          """
          self.transition_matrix = transition_matrix
          self.observation_matrix = observation_matrix
          self.initial_state_distribution = initial_state_distribution
          self.rel_tol = rel_tol
          self.ensure_dimensional_validity()
          self.ensure_row_stochasticity()

          self.ndim = transition_matrix.shape[0]
          self.mdim = observation_matrix.shape[1]

      def __str__(self):
          return '\n'.join((
              'transition:',
              str(self.transition_matrix), '',
              'observation:',
              str(self.observation_matrix), '',
              'initial states:',
              str(self.initial_state_distribution)))

      def ensure_dimensional_validity(self):
          """Raises an exception if the matrices' dimensions are not right.
          """
          tr_rows, tr_columns = self.transition_matrix.shape
          ob_rows, _ = self.observation_matrix.shape
          in_rows, in_columns = self.initial_state_distribution.shape

          if not (tr_rows == tr_columns == ob_rows == in_columns):
              raise ValueError('The number of transition rows, transition columns, observation rows and initial state distribution columns is not the same')

          if in_rows != 1:
              raise ValueError("The initial state distribution matrix should have one and only one row")

      def ensure_row_stochasticity(self):
          """Raises an exception if the matrices are not row-stochastic.
          """
          def fullofones(iterable):
              return all(math.isclose(el, 1, rel_tol = self.rel_tol) for el in iterable)

          if not fullofones(self.transition_matrix.sum(axis=1)):
              raise ValueError("The transition matrix is not row stochastic")

          if not fullofones(self.observation_matrix.sum(axis=1)):
              raise ValueError("The observation matrix is not row stochastic")

          if not fullofones(self.initial_state_distribution.sum(axis=1)):
              raise ValueError("The initial_state_distribution matrix is not row stochastic")

      def getinitialstate(self, i):
          return self.initial_state_distribution[0,i]
#+END_SRC

*** Tests
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

**** Initialisation

#+BEGIN_SRC ipython :shebang "#!/usr/bin/env python3" :eval never :exports none
  from markov import *
  import np
#+END_SRC

**** Création /from scratch/
#+BEGIN_SRC ipython 
  markovtest = markovmodel.fromscratch(3, 4)
  print(markovtest.transition_matrix)
#+END_SRC

#+RESULTS:
: [[0.31821417 0.31306151 0.36872432]
:  [0.33979492 0.31437166 0.34583341]
:  [0.32128992 0.36485099 0.31385909]]

**** Exemple prédiction de température
Il s'agit ici de tester la création des modèles de Markov en utilisant l'exemple de prédiction de température.

#+BEGIN_SRC ipython
  try:
      markovtemperature = markovmodel(
          np.matrix([[0.7, 0.3],
                     [0.4, 0.6]]),
          np.matrix([[0.1, 0.4, 0.5],
                     [0.7, 0.2, 0.1]]),
          np.matrix([[0.6, 0.4]])
      )
      print('transition:', markovtemperature.transition_matrix,
            'observation:', markovtemperature.observation_matrix,
            'initial states:', markovtemperature.initial_state_distribution,
            sep='\n')
  except Exception as e:
      print('construction failed:', str(e))
#+END_SRC

#+RESULTS:
: construction failed: name 'np' is not defined

** Forward

#+BEGIN_SRC ipython :results output silent

  def alpha_pass(markov, observations):
      """Implementation of the forward algorithm to compute the alpha_t values.

      Parameters
      ----------
      markov : markovchain

      observations : iterable

      Returns
      -------
      out : np.array
          The alpha_t values.
      """
      alpha = zeros(shape=(len(observations), markov.ndim))
      scale_factors = zeros(shape=(len(observations)))
    
      # alpha_zero initialization

      for i in range(0, markov.ndim):
          alpha[0, i] = markov.getinitialstate(i) * markov.observation_matrix[i, 0]
          scale_factors[0] += alpha[0, i]

      scale_factors[0] = 1 /scale_factors[0]
    
      for i in range(0, markov.ndim):
          alpha[0, i] *= scale_factors[0]

      # alpha_t computation
      for t in range(1, len(observations)):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  alpha[t, i] += alpha[t - 1, j] * markov.transition_matrix[j, i]
              alpha[t, i] *= markov.observation_matrix[i, observations[t]]
              scale_factors[t] += alpha[t, i]

          # scale alpha
          scale_factors[t] = 1 / scale_factors[t]
          for i in range(0, markov.ndim):
              alpha[t, i] *= scale_factors[t]

      return (alpha, scale_factors)
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:
#+BEGIN_SRC ipython
  observations = [0, 1, 0, 2]
  alpha_matrix, scales = alpha_pass(markovtemperature, observations)
  print(alpha_matrix)
  print(scales)
#+END_SRC

#+RESULTS:
: [[0.17647059 0.82352941]
:  [0.62348178 0.37651822]
:  [0.16880093 0.83119907]
:  [0.8039794  0.1960206 ]]
: [2.94117647 3.44129555 2.87543655 3.56816483]

**** backup
#+RESULTS:
: [[0.17647059 0.82352941]
:  [0.62348178 0.37651822]
:  [0.16880093 0.83119907]
:  [0.8039794  0.1960206 ]]

** Backward

#+BEGIN_SRC ipython :results output silent
  def beta_pass(markov, observations, scale_factors):
      """

      Parameters
      ----------
      markov : 

      observations : 

      Returns
      -------
      out : 

      """
      beta = zeros(shape=(len(observations), markov.ndim))

      # all elements of the last column take the last scale factor as value
      # np.vectorize(lambda _: scale_factors[-1])(beta.transpose()[-1])
      # for line in beta:
      #     line[-1] = scale_factors[-1]
      for i in range(0, markov.ndim):
          beta[-1, i] = scale_factors[-1]

      for t in reversed(range(0, len(observations) - 1)):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  beta[t, i] += markov.transition_matrix[i, j] * markov.observation_matrix[j, observations[t+1]] * beta[t + 1, j]

              # scale beta
              beta[t, i] *= scale_factors[t]

      return beta
#+END_SRC

*** Tests
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  beta_matrix = beta_pass(markovtemperature, observations, scales)
  print(beta_matrix)
#+END_SRC

#+RESULTS:
: [[3.1361635  2.89939354]
:  [2.86699344 4.39229044]
:  [3.898812   2.66760821]
:  [3.56816483 3.56816483]]

** Gamma et di-gamma

#+BEGIN_SRC ipython :results silent
  def gamma_digamma_pass(markov, observations, alpha, beta):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      alpha : 
    
      beta : 
    
      Returns
      -------
      out : 
    
      """
      digamma = zeros(shape=(len(observations), markov.ndim, markov.ndim))
      gamma = zeros(shape=(len(observations), markov.ndim))

      for t in range(0, len(observations) - 1):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  digamma[t, i, j] = alpha[t, i] * markov.transition_matrix[i, j] * markov.observation_matrix[j, observations[t + 1]] * beta[t + 1, j]
                  gamma[t, i] += digamma[t, i, j]

      # special case for the last gammas
      for i in range(0, markov.ndim - 1):
          gamma[-1, i] = alpha[-1, i]

      return (gamma, digamma)
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  gamma, digamma = gamma_digamma_pass(
      markovtemperature,
      observations,
      alpha_matrix,
      beta_matrix
  )
  print(gamma, '\n\n\n', digamma, sep='')
#+END_SRC

#+RESULTS:
#+begin_example
[[0.18816981 0.81183019]
 [0.51943175 0.48056825]
 [0.22887763 0.77112237]
 [0.8039794  0.        ]]


[[[0.14166321 0.0465066 ]
  [0.37776855 0.43406164]]

 [[0.17015868 0.34927307]
  [0.05871895 0.4218493 ]]

 [[0.21080834 0.01806929]
  [0.59317106 0.17795132]]

 [[0.         0.        ]
  [0.         0.        ]]]
#+end_example


*** =greek_pass=
La fonction =greek_pass= fait office de sucre syntaxique, pour faire toutes les passes définies précédemment en récupérant seulement ce qui nous intéresse, à savoir les gammas et di-gammas.

#+BEGIN_SRC ipython 
  def greek_pass(markov, observations):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      Returns
      -------
      out : 
    
      """
      alpha, scale_factors = alpha_pass(markov, observations)
      beta = beta_pass(markov, observations, scale_factors)
      return (*gamma_digamma_pass(markov, observations, alpha, beta), scale_factors)
#+END_SRC

**** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  gamma2, digamma2, scale_factors = greek_pass(markovtemperature, observations)
  if not np.array_equal(gamma, gamma2) or not np.array_equal(digamma, digamma2):
      print('gammas or digammas from greek_pass and from gamma_digamma_pass differ')
  else:
      print('gammas and digammas from greek_pass and from gamma_digamma_pass are the same')

  if not np.array_equal(scales, scale_factors):
      print('the scale factors from alpha_pass et greek_pass differ')
  else:
      print('the scale factors from alpha_pass et greek_pass are the same')
#+END_SRC

#+RESULTS:
: gammas and digammas from greek_pass and from gamma_digamma_pass are the same
: the scale factors from alpha_pass et greek_pass are the same

** Réestimation

*** Distribution initiale des états

#+BEGIN_SRC ipython
  def reestimate_initial_state_distribution(markov, gamma):
      """Use previously-calculated gamma values to do a re-estimation of the initial state distribution.

      Parameters
      ----------
      markov : 
    
      gamma : 
    
      Returns
      -------
      out : 
      """
      for i in range(0, markov.ndim):
          markov.initial_state_distribution[0, i] = gamma[0, i]
#+END_SRC

*** Transitions

#+BEGIN_SRC ipython
  def reestimate_transition_matrix(markov, gamma, digamma):
      """


          Parameters
          ----------
          markov : 

          gamma : 

          digamma : 

          Returns
          -------
          out : 

      """
      for i in range(0, markov.ndim):
          for j in range(0, markov.ndim):
              gamma_acc, digamma_acc = 0, 0
              for t in range(0, len(gamma) - 1):
                  gamma_acc += gamma[t, i]
                  digamma_acc += digamma[t, i, j]
              markov.transition_matrix[i, j] = digamma_acc / gamma_acc

      markov.ensure_row_stochasticity()
#+END_SRC

*** Observations

#+BEGIN_SRC ipython
  def reestimate_observation_matrix(markov, observations, gamma):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      gamma : 
      """
      for i in range(0, markov.ndim):
          for j in range(0, markov.mdim):
              gamma_acc_observed, gamma_acc_all = 0, 0
              for t in range(0, len(observations)):
                  if observations[t] == j:
                      gamma_acc_observed += gamma[t, i]
                  gamma_acc_all += gamma[t, i]
              markov.observation_matrix[i, j] = gamma_acc_observed / gamma_acc_all
#+END_SRC

*** Probabilité de la chaine d'observation
La probabilité de la chaine d'observation selon le modèle de Markov est utilisé pour mesurer l'avancement de l'entrainement de ce modèle.

#+BEGIN_SRC ipython
  def log_observation_sequence_probability(scale_factors):
      """Compute the log of the observation's sequence probability according to a Markov model, using the scales factors.

      Parameters
      ----------
      scale_factors : 

      Returns
      -------
      out : 
      """
      result = 0
      for i in range(0, len(scale_factors)):
          result += math.log(scale_factors[i])
      return -result

#+END_SRC

*** Modèle
On utilise les trois fonctions de réestimation précédentes pour réestimer le modèle dans sa globalité, à partir de la chaine des observations.

#+BEGIN_SRC ipython
  def reestimate_markov_model(markov, observations):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      Returns
      -------
      out : 
      """
      gamma, digamma, scale_factors = greek_pass(markov, observations)
      reestimate_initial_state_distribution(markov, gamma)
      reestimate_transition_matrix(markov, gamma, digamma)
      reestimate_observation_matrix(markov, observations, gamma)
      return log_observation_sequence_probability(scale_factors)
#+END_SRC

*** Boucle de réestimation
L'entrainement d'un modèle de Markov se fait en répétant des réevaluations.
On arrête la boucle de réestimation lorsque un nombre pré-déterminé a été achevé ou lorsque la réestimation cesse d'apporter des améliorations par rapport à l'itération précédente.

#+BEGIN_SRC ipython
  def train_markov_model(markov, observations, max_iterations=200):
      """

      Parameters
      ----------
      markov : 

      observations : 

      max_iterations : 

      Returns
      -------
      out : 
      """
      _, scale_factors = alpha_pass(markov, observations)
      bestlogprob = log_observation_sequence_probability(scale_factors)
      bestmodel = deepcopy(markov)

      for i in range(1, max_iterations):
          logprob = reestimate_markov_model(markov, observations)
          markov.ensure_row_stochasticity()
          if logprob > bestlogprob:
              bestmodel = deepcopy(markov)
              bestlogprob = logprob

      markov = deepcopy(bestmodel)
      return bestlogprob
#+END_SRC

L'initialisation des matrices d'un modèle de Markov est délicate et il est difficile de garantir que des matrices initialisées aléatoirement vont produire un bon résultat.
D'où l'idée d'initialiser aléatoirement $X$ modèles, de les entrainer $Y$ fois, et de finir l'entrainement du modèle le plus prometteur.

#+BEGIN_SRC ipython
  def train_best_markov_model(N, M, observations, nb_candidates, train_iter, max_iter):
      bestmodel = markovmodel.fromscratch(N, M)
      bestprob = train_markov_model(bestmodel, observations, train_iter)

      for i in range(0, nb_candidates - 1):
          candidate = markovmodel.fromscratch(N, M)
          candidateprob = train_markov_model(candidate, observations, train_iter)

          if candidateprob > bestprob:
              bestprob = candidateprob
              bestmodel = deepcopy(candidate)

      print(bestprob)
      print(bestmodel)
      train_markov_model(bestmodel, observations, max_iter - train_iter)
      return bestmodel
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  from copy import deepcopy
  markov_copy = deepcopy(markovtemperature)
  print(markov_copy)
  train_markov_model(markov_copy, observations, 10)
  print(markov_copy)
#+END_SRC

#+RESULTS:
#+begin_example
transition:
[[0.7 0.3]
 [0.4 0.6]]

observation:
[[0.1 0.4 0.5]
 [0.7 0.2 0.1]]

initial states:
[[0.6 0.4]]
the model stopped improving at iteration 9
transition:
[[3.80741949e-287 1.00000000e+000]
 [1.00000000e+000 0.00000000e+000]]

observation:
[[9.52278575e-288 5.00000000e-001 5.00000000e-001]
 [1.00000000e+000 0.00000000e+000 0.00000000e+000]]

initial states:
[[1.69480811e-290 1.00000000e+000]]
#+end_example



* Analyse de texte assistée par un modèle de Markov caché

#+BEGIN_SRC ipython
  def map_el_to_int(iterable, alphabet):
      """Map all the elements of an iterable to their index in an alphabet.
      If an element is not in the alphabet, it will be ignored.

      Parameters
      ----------
      iterable : iterable
          The iterable to map.

      alphabet : str
          The letters to keep.

      Returns
      -------
      out : list of int
          The list containing the index of each character in the input string.
      """
      indexation = {letter: index for index, letter in enumerate(alphabet)}
      return (indexation[char] for char in iterable if char in alphabet)

  def markov_alphabetical_analysis(markov, alphabet):
      observation_scores = [[letter,
                             ,*(markov.observation_matrix[state, index]
                                for state in range(0, markov.ndim))]
                            for index, letter in enumerate(alphabet)]

      letter_groups = [list() for _ in range(0, markov.ndim)]
      ungroupables = []

      for letterindex, letter in enumerate(alphabet):
          maxindex = 0
          for state in range(1, markov.ndim):
              if markov.observation_matrix[state, letterindex] >\
                 markov.observation_matrix[maxindex, letterindex]:
                  maxindex = state
              if markov.observation_matrix[maxindex, letterindex] == 0:
                  ungroupables.append(letter)
              else:
                  letter_groups[maxindex].append(letter)

      return observation_scores, letter_groups, ungroupables

#+END_SRC

* noweb
:PROPERTIES:
:header-args:ipython: :tangle no :session none :results silent :eval never
:END:

** corpuses
#+NAME: browncorpus
#+BEGIN_SRC ipython
  with open('brown50000.txt', 'r') as brownfile:
      corpus = brownfile.read().replace('\n', '')
#+END_SRC

#+NAME: repcorpus
#+BEGIN_SRC ipython
  with open('1999-05-17.txt', 'r') as repfile:
      corpus = repfile.read().replace('\n', '')
#+END_SRC

#+NAME: wikificorpus
#+BEGIN_SRC ipython
  with open('wiki_fi_50000.txt', 'r') as suofile:
      corpus = suofile.read().replace('\n', '')
#+END_SRC

** Alphabets

#+NAME: latinalphabet
#+BEGIN_SRC ipython
  alphabet = 'abcdefghijklmnopqrstuvwxyz '
#+END_SRC

#+NAME: frenchalphabet
#+BEGIN_SRC ipython
  alphabet = 'aàâæbcçdeéèêëfghiîïjklmnoôœpqrstuùûüvwxyÿz '
#+END_SRC

#+NAME: finnishalphabet
#+BEGIN_SRC ipython
  alphabet = 'aäåbcdefghijklmnoöpqrstuvwxyz '
#+END_SRC

** Observations

#+NAME: rawObservations
#+BEGIN_SRC ipython
  observations = list(islice(
      map_el_to_int(corpus, alphabet),
      0, 50000))
#+END_SRC

#+NAME: observationsNoSpecials
#+BEGIN_SRC ipython
  def translate(iterable, translation_table):
      for el in iterable:
          if el in translation_table:
              for tr in translation_table[el]:
                  yield tr
          else:
              yield el

  translations = {'à': 'a',
                  'â': 'a',
                  'æ': 'ae',
                  'ç': 'c',
                  'é': 'e',
                  'è': 'e',
                  'ê': 'e',
                  'ë': 'e',
                  'î': 'i',
                  'ï': 'i',
                  'ô': 'o',
                  'œ': 'oe',
                  'ù': 'u',
                  'û': 'u',
                  'ü': 'u',
                  'ÿ': 'y',
                  '\'': ' ',
                  '-': ' '}

  observations = list(islice(
      map_el_to_int(translate(corpus, translations), alphabet),
      0, 50000))
#+END_SRC

** Affichage
#+NAME: printprobas
#+BEGIN_SRC ipython
  _, scale_factors = alpha_pass(model, observations)
  print('score', log_observation_sequence_probability(scale_factors))
#+END_SRC

#+NAME: printresults
#+BEGIN_SRC ipython
  scoretable, groups, ungroupables = markov_alphabetical_analysis(model, alphabet)
  print(scoretable)
  print(groups)
#+END_SRC

# #+NAME: printmodel
# #+BEGIN_SRC ipython
#   print('#+CAPTION: Matrice des transitions')
#   try:
#       name
#       print('#+NAME:', name + 'tra')
#   except NameError:
#       pass
#   print(orgmodetable(model.transition_matrix))
#   print()

#   print('#+CAPTION: Matrice des observations')
#   try:
#       name
#       print('#+NAME:', name + 'obs')
#   except NameError:
#       pass
#   print(orgmodetable(model.observation_matrix))
#   print()

#   print('#+CAPTION: Matrice des états initiaux')
#   try:
#       name
#       print('#+NAME:', name + 'ini')
#   except NameError:
#       pass
#   print(orgmodetable(model.initial_state_distribution))
# #+END_SRC

#+NAME: markov_report
#+BEGIN_SRC ipython
  def latexify(char):
      if char == ' ':
          return '\\textvisiblespace'
      return char


  scoretable, groups, ungroupables = markov_alphabetical_analysis(model, alphabet)
  scoretable = [[latexify(line[0]),
                 ,*('${:.3f}$'.format(probas * 100) for probas in line[1:])]
                for line in scoretable]
  scoretable.insert(0, ['Caractère', 'État 1 (%)', 'État 2 (%)'])
  print('#+ATTR_LATEX: :align l l l')
  caption = '#+CAPTION: Probabilités d\'observation'

  try:
      descr
      caption = caption + descr
  except NameError:
      pass
  print(caption)

  try:
      name
      print('#+NAME:', name + 'rep')
  except NameError:
      pass
  print(orgmodetable(scoretable, header=True), '\n\n\n')

  groupstable = [[' '.join((latexify(char) for char in group))
                    for group in groups] ]
  groupstable.insert(0, ['Groupe 1', 'Groupe 2'])

  if len(ungroupables) > 0:
      groupstable[0].append(
          'Hors groupes')
      groupstable[1].append(
          ' '.join(latexify(char) for char in ungroupables))

  caption = '#+CAPTION: Groupes formés'
  try:
      descr
      caption = caption + descr
  except NameError:
      pass
  print(caption)

  try:
      name
      print('#+NAME:', name + 'grp')
  except NameError:
      pass
  print(orgmodetable(groupstable, header=True))
#+END_SRC

** Entrainement

#+NAME: trainbest
#+BEGIN_SRC ipython
  model = train_best_markov_model(
      2, len(alphabet),
      observations,
      nb_candidates=3,
      train_iter=8,
      max_iter=100)
#+END_SRC

#+NAME: trainfromscratch
#+BEGIN_SRC ipython
  model = markovmodel.fromscratch(2, len(alphabet))
  train_markov_model(model, observations, 100)
#+END_SRC

** Divers

#+NAME: deforgmodetable
#+BEGIN_SRC ipython
def orgmodetable(matrix, header=False):
    maxlen = [0] * len(matrix[0])
    for line in matrix:
        for i, cell in enumerate(line):
            if len(maxlen) <= i or len(str(cell)) > maxlen[i]:
                maxlen[i] = len(str(cell))

    def orgmodeline(line, fill=' '):
        joinsep = fill + '|' + fill
        return '|' + fill + joinsep.join(
            str(cell) + fill * (mlen - len(str(cell)))
            for cell, mlen in zip(line, maxlen)
        ) + fill + '|'

    result = ''
    if header:
        result = orgmodeline(matrix[0]) + '\n' + \
            orgmodeline(('-') * len(maxlen), fill='-') + '\n'
        matrix = matrix[1:]
    result += '\n'.join(orgmodeline(line) for line in matrix)
    return result
#+END_SRC

#+NAME: markovimport
#+BEGIN_SRC ipython
  from itertools import islice
  from markov import *
#+END_SRC

#+NAME: extractresults
#+BEGIN_SRC sh
  best=$(grep -nH score $pattern* | sort -k 2 -t ' ' -gr | head -n1)
  file=$(echo $best | cut -f 1 -d ':')
  line=$(echo $best | cut -f 2 -d ':')
  tail --lines=+$((line + 1)) $file
#+END_SRC

* Introduction                                                       :export:
:PROPERTIES:
:UNNUMBERED: t
:END:
\addcontentsline{toc}{chapter}{Introduction}
L'expérience de "Marvin le martien" (Stamp 2018) montre qu'il est possible d'extraire des caractéristiques linguistiques à partir d'un corpus de petite taille (50000 caractères), et ce sans connaissances préalables sur la langue du corpus.
Cette expérience consiste à entrainer des modèles de Markov cachés comprenant deux états sur un corpus en anglais.
Les deux états ainsi formés regroupent d'une part les consonnes et d'autre part les voyelles.

Nous allons dans un premier temps reproduire cette expérience sur le corpus évoqué dans (Stamp 2018). Nous allons par la suite mener une expérience similaire sur un corpus en langue française. Finalement cette même expérience sera faite sur un corpus finnois.

Le choix a été fait d'implémenter en python l'algorithme d'entrainement d'un modèle de Markov caché. Cette implémentation est disponible sur github à l'adresse suivante : https://github.com/mooss/ruskea.

* Reproduction de l'expérience sur le /Brown corpus/                 :export:

Cette section décrit la démarche entreprise pour reproduire l'expérience de "Marvin le martien" sur le /Brown corpus/.

Dans un premier temps la méthode utilisée pour extraire les 50000 premiers caractères du /Brown corpus/ va être détaillée.
Ensuite, une reproduction de l'expérience va être effectuée en utilisant les matrices proposées dans (Stamp 2018).
Finalement, l'expérience va être reproduite en initialisant les matrices procéduralement.
** Extraction des 50 000 premiers caractères du /Brown corpus/

La première étape est d'extraire les caractères nous intéressant depuis le /Brown corpus/.
En effet, le /Brown corpus/ est distribué avec les annotations intégrées et il faut donc les supprimer.

La bibliothèque NTLK est utilisée pour télécharger le corpus.
Les 50000 premiers caractères de ce corpus sont écrits dans le fichier =brown50000.txt=, en utilisant le script =brownextract.py= :
#+BEGIN_SRC ipython :session brownextract :results silent :tangle brownextract.py :eval never :shebang "#!/usr/bin/env python3"
  import nltk
  nltk.download('brown')
  nltk.download('nonbreaking_prefixes')
  nltk.download('perluniprops')
  from nltk.corpus import brown
  from nltk.tokenize.moses import MosesDetokenizer

  mdetok = MosesDetokenizer()

  def remove_brown_annotations(sentence):
      return mdetok.detokenize(
          ' '.join(sent).replace('``', '"')\
          .replace("''", '"')\
          .replace('`', "'").split(),
          return_str=True)


  maxnbchar = 50000
  currentnbchar = 0
  charbuffer = []

  alphabet = 'abcdefghijklmnopqrstuvwxyz '

  for sent in brown.sents():
      for char in remove_brown_annotations(sent):
          if currentnbchar < maxnbchar and char in alphabet:
              charbuffer.append(char)
              currentnbchar += 1

  output = 'brown50000.txt'
  with open(output, "w") as text_file:
      text_file.write(''.join(charbuffer))

#+END_SRC

** Matrices prédéfinies
:PROPERTIES:
:header-args:ipython: :tangle brownmarvin.py :session brownmarvin_exec :results output replace drawer
:END:
Les matrices de transitions, observations, et des états initiaux sont initialisées selon les valeurs fournies dans l'article de Mark Stamp.

#+BEGIN_SRC ipython :exports code :shebang "#!/usr/bin/env python3" :noweb yes :results silent
  from numpy import array
  from markov import *

  marvin_transition = array([[0.47468, 0.52532],
                             [0.51656, 0.48344]])
  marvin_observation = array(
      [[0.03688, 0.03735, 0.03408, 0.03455, 0.03828, 0.03782, 0.03922, 0.03688, 0.03408, 0.03875, 0.04062, 0.03735, 0.03968, 0.03548, 0.03735, 0.04062, 0.03595, 0.03641, 0.03408, 0.04062, 0.03548, 0.03922, 0.04062, 0.03455, 0.03595, 0.03408, 0.03408],
       [0.03397, 0.03909, 0.03537, 0.03537, 0.03909, 0.03583, 0.03630, 0.04048, 0.03537, 0.03816, 0.03909, 0.03490, 0.03723, 0.03537, 0.03909, 0.03397, 0.03397, 0.03816, 0.03676, 0.04048, 0.03443, 0.03537, 0.03955, 0.03816, 0.03723, 0.03769, 0.03955]]
  )
  marvin_initial = array([[0.51316, 0.48684]])

  <<browncorpus>>

  <<latinalphabet>>

  model = markovmodel(marvin_transition, marvin_observation, marvin_initial, rel_tol=1e-3)

  train_markov_model(model,
                     list(map_el_to_int(corpus, alphabet)),
                     max_iterations=100)

#+END_SRC

#+BEGIN_SRC ipython :exports none :eval no :noweb yes
  <<printresults>>
#+END_SRC

Une tolérence relative de 1e^{-3} est appliquée à la construction du modèle pour vérifier la stochasticité des matrice. Sans cette tolérance élevé, l'étape de vérification de la stochasticité des matrices échoue.

Les valeurs ont été copiées telles quelles depuis l'article. Il est probables que ces valeurs aient été arrondies par l'auteur de l'article, d'où la nécessité d'assouplir le test de stochasticité.

*** Résultats
Les résultats sont synthétisés dans les tables [[marvinrep]] et [[marvingrp]].

La table [[marvinrep]] correspond à la transposée de la matrice d'observation du modèle de Markov entrainé, avec comme information supplémentaire en première colonne le caractère auquel correspondent les probabilités d'apparition des colonnes suivantes.
Les probabilités d'apparition sont rapportées sous forme de pourcentages, afin d'être plus lisibles.

La table [[marvingrp]] regroupe les caractères selon l'état pour lequel il ont la plus grande probabilité d'apparition.
Les résultats des autres expériences seront également présentés sous cette forme.

Les résultats obtenus sont similaires à ceux présentés dans (Stamp 2018), à savoir les voyelles (moins y) d'un côté et les consonnes (plus y) de l'autre.

Bien que la tendance générale soit la même que dans l'article original, les valeurs des matrices de probabilité d'observation diffèrent[fn:orgrepcomp]. L'article n'explicite pas quelle démarche a été utilisée pour extraire les premiers caractères du /Brown corpus/. La démarche utilisée ici repose sur la supposition que la méthode =nltk.corpus.brown.sents()= parcours les phrases du /Brown corpus/ de la même manière que dans l'article. Il est probable que les méthodes utilisées diffèrent, résultant ainsi en une chaine d'observation et en un modèle différents.

[fn:orgrepcomp] Les probabilités d'observation de l'article original sont visibles dans la table [[stampobsmatrix]].


#+BEGIN_SRC ipython :tangle no :exports results :noweb yes
  name = 'marvin'
  descr = ' - /Brown corpus/ - Matrices pré-initialisées'
  <<markov_report>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
#+CAPTION: Probabilités d'observation - /Brown corpus/ - Matrices pré-initialisées
#+NAME: marvinrep
| Caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| a                 | $0.050$    | $13.487$   |
| b                 | $2.231$    | $0.000$    |
| c                 | $5.362$    | $0.022$    |
| d                 | $7.025$    | $0.000$    |
| e                 | $0.267$    | $21.161$   |
| f                 | $3.609$    | $0.000$    |
| g                 | $2.637$    | $0.204$    |
| h                 | $5.415$    | $2.016$    |
| i                 | $0.000$    | $12.127$   |
| j                 | $0.238$    | $0.000$    |
| k                 | $0.518$    | $0.288$    |
| l                 | $7.328$    | $0.328$    |
| m                 | $3.917$    | $0.000$    |
| n                 | $12.077$   | $0.000$    |
| o                 | $0.013$    | $13.061$   |
| p                 | $3.513$    | $0.122$    |
| q                 | $0.162$    | $0.000$    |
| r                 | $10.606$   | $0.000$    |
| s                 | $11.239$   | $0.033$    |
| t                 | $15.192$   | $0.659$    |
| u                 | $0.000$    | $4.418$    |
| v                 | $1.718$    | $0.000$    |
| w                 | $2.255$    | $0.000$    |
| x                 | $0.477$    | $0.000$    |
| y                 | $2.643$    | $0.115$    |
| z                 | $0.121$    | $0.000$    |
| \textvisiblespace | $1.385$    | $31.959$   | 



#+CAPTION: Groupes formés - /Brown corpus/ - Matrices pré-initialisées
#+NAME: marvingrp
| Groupe 1                                  | Groupe 2                    |
|-------------------------------------------|-----------------------------|
| b c d f g h j k l m n p q r s t v w x y z | a e i o u \textvisiblespace |
:END:

#+ATTR_LATEX: :align l l l
#+CAPTION: Probabilités d'observation (Stamp 2018)
#+NAME: stampobsmatrix
| Caractère         | État 1 (%) | État 2 (%) |
|-------------------+------------+------------|
| a                 |     13.845 |      0.075 |
| b                 |      0.000 |      2.311 |
| c                 |      0.062 |      5.614 |
| d                 |      0.000 |      6.937 |
| e                 |     21.404 |      0.000 |
| f                 |      0.000 |      3.559 |
| g                 |      0.081 |      2.724 |
| h                 |      0.066 |      7.278 |
| i                 |     12.275 |      0.000 |
| j                 |      0.000 |      0.365 |
| k                 |      0.182 |      0.703 |
| l                 |      0.049 |      7.231 |
| m                 |      0.000 |      3.889 |
| n                 |      0.000 |     11.461 |
| o                 |     13.156 |      0.000 |
| p                 |      0.040 |      3.674 |
| q                 |      0.000 |      0.153 |
| r                 |      0.000 |     10.225 |
| s                 |      0.000 |     11.042 |
| t                 |      1.102 |     14.392 |
| u                 |      4.508 |      0.000 |
| v                 |      0.000 |      1.621 |
| w                 |      0.000 |      2.303 |
| x                 |      0.000 |      0.447 |
| y                 |      0.019 |      2.587 |
| z                 |      0.000 |      0.110 |
| \textvisiblespace |     33.211 |      1.298 |

** Matrices générées procéduralement
:PROPERTIES:
:header-args:ipython: :session brownrandomexec :results output replace drawer :tangle brownrandom.py
:END:

L'article de Mark Stamp ne fournit que peu de détails concernant l'initialisation des matrices de transition, d'observation et de répartition initiale des états.
En effet, la seule indication donnée est d'initialiser les éléments de chaque ligne à environ $1/X$, $X$ étant le nombre d'éléments dans la ligne.

Le probème est qu'en utilisant des matrices d'une forme similaire à celle proposée dans l'article, les résultats sont susceptible de différer grandement.

Après beaucoup d'essais infructeux, une solution satisfaisante a été trouvée ; elle consiste à initialiser les matrices à $1/X$ et parcourir chacune des lignes en y ajoutant ou en retranchant un nombre aléatoire entre $a$ et $b$, dont les valeurs sont dans la table [[bornes_alea]]. Les lignes ainsi crées sont ensuite rendues stochastiques en multipliant chacune de leurs cases par une constante $N$ telle que :
$$N = \frac{1}{\sum\limits_{el \in ligne}^ {}{el}}$$

#+CAPTION: Bornes aléatoires
#+NAME: bornes_alea
| Matrice      |   $a$ |   $b$ |
| Transitions  | 0.000 | 0.005 |
| Observations |  0.02 | 0.025 |
| État initial | 0.001 | 0.005 |

Cette solution est implémentée dans la méthode =markovmodel.fromscratch=, visible dans le fichier =markov.py=.

#+BEGIN_SRC ipython :exports code :noweb yes :shebang "#!/usr/bin/env python3" :results silent
  <<markovimport>>

  <<browncorpus>>

  <<latinalphabet>>

  <<rawObservations>>

  <<trainfromscratch>>

#+END_SRC

#+BEGIN_SRC ipython :exports none :eval no :noweb yes
  <<printresults>>
#+END_SRC

*** Résultats

Des résultats similaires à ceux de l'expérience originale ont été retrouvés dans 45 des 50 exécutions du script ci-dessus. Les tables [[randbrownrep]] et [[randbrowngrp]] montrent le résultat d'une de ces exécutions.

#+BEGIN_SRC ipython :tangle no :exports results :noweb yes
  name = 'randbrown'
  descr = ' - /Brown corpus/ - Matrices initialisées procéduralement'
  <<markov_report>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
#+CAPTION: Probabilités d'observation - /Brown corpus/ - Matrices initialisées procéduralement
#+NAME: randbrownrep
| Caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| a                 | $0.000$    | $14.258$   |
| b                 | $2.121$    | $0.000$    |
| c                 | $5.097$    | $0.024$    |
| d                 | $6.679$    | $0.000$    |
| e                 | $0.000$    | $22.566$   |
| f                 | $3.432$    | $0.000$    |
| g                 | $2.427$    | $0.303$    |
| h                 | $7.052$    | $0.059$    |
| i                 | $0.000$    | $12.774$   |
| j                 | $0.227$    | $0.000$    |
| k                 | $0.513$    | $0.282$    |
| l                 | $7.283$    | $0.004$    |
| m                 | $3.724$    | $0.000$    |
| n                 | $11.483$   | $0.000$    |
| o                 | $0.000$    | $13.771$   |
| p                 | $3.381$    | $0.084$    |
| q                 | $0.154$    | $0.000$    |
| r                 | $10.084$   | $0.000$    |
| s                 | $10.718$   | $0.000$    |
| t                 | $13.550$   | $1.665$    |
| u                 | $0.000$    | $4.654$    |
| v                 | $1.633$    | $0.000$    |
| w                 | $2.144$    | $0.000$    |
| x                 | $0.453$    | $0.000$    |
| y                 | $2.081$    | $0.590$    |
| z                 | $0.115$    | $0.000$    |
| \textvisiblespace | $5.647$    | $28.966$   | 



#+CAPTION: Groupes formés - /Brown corpus/ - Matrices initialisées procéduralement
#+NAME: randbrowngrp
| Groupe 1                                  | Groupe 2                    |
|-------------------------------------------|-----------------------------|
| b c d f g h j k l m n p q r s t v w x y z | a e i o u \textvisiblespace |
:END:


* Expérience sur un corpus français                                  :export:
Cette section s'appuie sur un corpus contenant des articles du journal l'Est Républicain, publiés en 1999.
Le corpus est disponible à l'adresse suivante : http://www.cnrtl.fr/corpus/estrepublicain/.

** Extraction du texte
Les articles sont contenus dans des fichiers =XML=. Le script suivant est utilisé pour récupérer le texte des articles en ignorant le balisage.

Le texte ainsi extrait est sauvegardé dans le fichier =1999-05-17.txt=.

L'alphabet utilisé correspond à celui décrit dans Wikipédia (https://fr.wikipedia.org/wiki/Alphabet_fran%C3%A7ais), soit les 26 lettres fondamentales, les 13 voyelles accentuées (=àâéèêëîïôùûüÿ=), les deux ligatures (=œæ=), et le c cédille. L'espace se rajoute à ces 42 lettres.

#+BEGIN_SRC ipython :tangle repextract.py :results silent :eval no-export :shebang "#!/usr/bin/env python3"
  import xml.etree.ElementTree as ET
  from itertools import chain

  root = ET.parse('1999-05-17.xml').getroot()
  articles = root.findall('./tei:text/tei:body/tei:div/tei:div/',
                          {'tei': 'http://www.tei-c.org/ns/1.0'})

  alphabet = ' aàâæbcçdeéèêëfghiîïjklmnoôœpqrstuùûüvwxyÿz'
  # print(list(root))
  # print(articles)

  def filterspaces(iterable):
      prevwasspace = True
      for char in iterable:
          if char == ' ':
              if not prevwasspace:
                  prevwasspace = True
                  yield char
          else:
              yield char
              prevwasspace = False


  charbuffer = (char
                for article in articles
                for paragraph in article.itertext()
                for char in paragraph.lower()
                if char in alphabet)

  with open('1999-05-17.txt', 'w') as output:
      output.write(''.join(filterspaces(charbuffer)))
#+END_SRC

Cette approche a ses limites, par exemple, il y a beaucoup de =h= isolés à cause de la notation des heures (exemple : de 20h à 20h30). Par ailleurs la suppression de certain caractères spéciaux mène à des juxtapositions indésirables (exemple : saint-mihiel \rightarrow saintmihiel, l'heure \rightarrow lheure).

Il serait possible de créer des règles pour traiter ces cas particuliers. Cependant, ils semblent être statistiquement insignifiants, c'est pourquoi le choix a été fait de ne pas s'en soucier.

** Analyse du texte
:PROPERTIES:
:header-args:ipython: :tangle repfrench.py :session repfrench :results output replace drawer
:END:

Que ce soit à cause de la taille accrue de l'alphabet, ou des particularités du corpus, les résultats sont moins cohérents au fil des exécutions que lors de l'expérience sur le /Brown corpus/.

Une nouvelle approche s'est donc imposée.
En plus du système d'initialisation de matrices précédemment décrit, $N$ modèles sont entrainés $M$ fois et le meilleur d'entre eux est selectionné pour continuer l'entrainement jusquà $100$.
On a ici $N=3$ et $M=8$.

Cette approche n'est cependant pas suffisante, les résultats de plusieurs exécutions restent grandement différents.
Pour être sûr d'obtenir de bons résultats, le script est exécuté $50$ fois et le meilleur modèle est conservé, c'est à dire celui maximisant la probabilité de la chaine d'observation.

#+BEGIN_SRC ipython :exports code :shebang "#!/usr/bin/env python3" :noweb yes
  <<markovimport>>

  <<repcorpus>>

  <<frenchalphabet>>

  <<rawObservations>>

  <<trainbest>>
#+END_SRC

#+BEGIN_SRC ipython :exports none :eval no :noweb yes
  name = 'rawfrench'
  descr = ' - Est républicain - Alphabet complet'
  <<printprobas>>

  <<deforgmodetable>>


  <<markov_report>>
#+END_SRC

*** Résultats

La table [[rawfrenchgrp]] indique les groupes formés par le modèle. Les caractères =æïüÿ= n'étaient pas présents dans le corpus. Les deux groupes formés sont clairement les voyelles et les consonnes, à l'exception des caractères =àëù= qui ont été classés dans le même groupe que les consonnes.

Un autre résultat remarquable est que comme pour l'anglais, le =y= est classifié avec les consonnes. Cependant, les probabilités d'observations dans l'état consonne et dans l'état voyelle pour le =y= sont plus proches en français qu'en anglais[fn:ycomp].

[fn:ycomp] Comparer les tables [[rawfrenchrep]] et [[randbrownrep]].


#+BEGIN_SRC sh :shebang "#!/usr/bin/env bash" :eval never :exports none :tangle repfrench50times.sh :exports none
  for((i=0; i<50; ++i));
  do
      ./repfrench.py > repfrench_execution_$i &
  done
#+END_SRC

#+BEGIN_SRC sh :tangle bestrepfrench.sh :exports results :results replace drawer :shebang "#!/usr/bin/env bash" :noweb yes
  pattern='repfrench_execution_'
  <<extractresults>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
#+CAPTION: Probabilités d'observation - Est républicain - Alphabet complet
#+NAME: rawfrenchrep
| Caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| a                 | $12.501$   | $0.000$    |
| à                 | $0.000$    | $1.261$    |
| â                 | $0.088$    | $0.000$    |
| æ                 | $0.000$    | $0.000$    |
| b                 | $0.118$    | $1.825$    |
| c                 | $0.340$    | $6.146$    |
| ç                 | $0.000$    | $0.083$    |
| d                 | $0.000$    | $7.753$    |
| e                 | $21.872$   | $0.000$    |
| é                 | $4.179$    | $0.000$    |
| è                 | $0.560$    | $0.000$    |
| ê                 | $0.214$    | $0.000$    |
| ë                 | $0.000$    | $0.013$    |
| f                 | $0.006$    | $2.195$    |
| g                 | $0.000$    | $2.018$    |
| h                 | $0.000$    | $2.347$    |
| i                 | $10.730$   | $0.000$    |
| î                 | $0.044$    | $0.000$    |
| ï                 | $0.000$    | $0.000$    |
| j                 | $0.000$    | $0.687$    |
| k                 | $0.000$    | $0.091$    |
| l                 | $0.000$    | $10.805$   |
| m                 | $0.000$    | $4.943$    |
| n                 | $0.000$    | $12.994$   |
| o                 | $8.097$    | $0.000$    |
| ô                 | $0.085$    | $0.000$    |
| œ                 | $0.042$    | $0.020$    |
| p                 | $0.371$    | $4.843$    |
| q                 | $0.006$    | $1.184$    |
| r                 | $0.000$    | $12.525$   |
| s                 | $0.000$    | $13.594$   |
| t                 | $1.434$    | $10.615$   |
| u                 | $8.126$    | $0.053$    |
| ù                 | $0.000$    | $0.048$    |
| û                 | $0.033$    | $0.000$    |
| ü                 | $0.000$    | $0.000$    |
| v                 | $0.000$    | $2.474$    |
| w                 | $0.000$    | $0.044$    |
| x                 | $0.084$    | $1.020$    |
| y                 | $0.271$    | $0.304$    |
| ÿ                 | $0.000$    | $0.000$    |
| z                 | $0.000$    | $0.114$    |
| \textvisiblespace | $30.801$   | $0.000$    | 



#+CAPTION: Groupes formés - Est républicain - Alphabet complet
#+NAME: rawfrenchgrp
| Groupe 1                                    | Groupe 2                                          | Hors groupes |
|---------------------------------------------|---------------------------------------------------|--------------|
| a â e é è ê i î o ô œ u û \textvisiblespace | à b c ç d ë f g h j k l m n p q r s t ù v w x y z | æ ï ü ÿ      |
:END:

* Expérience sur un corpus finnois                                   :export:
Le corpus va être extrait du dernier /dump/ du wikipédia finnois (https://dumps.wikimedia.org/fiwiki/latest/fiwiki-latest-pages-articles.xml.bz2), à l'aide de la bibliothèque gensim.

** Extraction du texte

#+BEGIN_SRC bash :tangle download_latest_finnish_wikipedia_dump.sh :eval never :exports none :shebang "#!/usr/bin/env bash"
  wget -q --show-progress https://dumps.wikimedia.org/fiwiki/latest/fiwiki-latest-pages-articles.xml.bz2
#+END_SRC

Le script suivant (=make_wiki_corpus.py=), partiellement recopié depuis https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html, est utilisé pour transformer le /dump/ wikipédia en un fichier texte.

Le script original a été modifié afin de n'extraire que les $N$ premiers caractères.

#+BEGIN_SRC ipython :tangle make_wiki_corpus.py :shebang "#!/usr/bin/env python3" :exports code :eval never
  """
  Creates a corpus from Wikipedia dump file.
  Inspired by:
  https://github.com/panyang/Wikipedia_Word2vec/blob/master/v1/process_wiki.py
  """

  import sys
  from itertools import chain
  from gensim.corpora import WikiCorpus

  def get_n_chars(wiki, n):
      nbchar = 0
      charbuffer = []
      for text in wiki.get_texts():
          for word in text:
              for char in chain(word, ' '):
                  if nbchar < n:
                      nbchar += 1
                      charbuffer.append(char)
                  else:
                      return charbuffer
      return charbuffer


  def make_corpus(in_f, out_f, maxchar):
      wiki = WikiCorpus(in_f)
      charbuffer = get_n_chars(wiki, maxchar)
      with open(out_f, 'w') as output:
          output.write(''.join(charbuffer))


  if __name__ == '__main__':

      if len(sys.argv) != 4:
          print('Usage: python make_wiki_corpus.py <wikipedia_dump_file> <processed_text_file> <number_of_characters>')
          sys.exit(1)
      in_f = sys.argv[1]
      out_f = sys.argv[2]
      maxchar = int(sys.argv[3])
      make_corpus(in_f, out_f, maxchar)
#+END_SRC

Les 50000 premiers caractères du texte sont extraits dans le fichier =wiki_fi_50000.txt=.

#+BEGIN_SRC bash :tangle wikifiextract.sh :shebang "#!/usr/bin/env bash" :exports code :eval never
  ./make_wiki_corpus.py fiwiki-latest-pages-articles.xml.bz2 wiki_fi_50000.txt 50000
#+END_SRC

** Analyse du texte
:PROPERTIES:
:header-args:ipython: :tangle wikifinnish.py :eval never
:END:

L'approche adoptée est la même que celle utilisée pour le corpus français ; $N$ modèles sont entrainés $M$ fois, le meilleur est par la suite entrainé $100-N$ fois. Ce processus est répété 50 fois, et les résultats du meilleur modèle sont conservés.

#+BEGIN_SRC ipython :exports code :shebang "#!/usr/bin/env python3" :noweb yes
  <<markovimport>>

  <<wikificorpus>>

  <<finnishalphabet>>

  <<rawObservations>>

  <<trainbest>>
#+END_SRC

#+BEGIN_SRC ipython :exports none :eval no :noweb yes
  name = 'finnish'
  descr = ' - Wikipédia finnois'
  <<printprobas>>

  <<deforgmodetable>>


  <<markov_report>>
#+END_SRC

#+BEGIN_SRC sh :shebang "#!/usr/bin/env bash" :eval never :exports none :tangle wikifinnish50times.sh :exports none
  for((i=0; i<50; ++i));
  do
      ./wikifinnish.py > wikifinnish_execution_$i &
  done
#+END_SRC

*** Résultats
L'alphabet finnois est composé des 26 caractères de l'alphabet latin, et de trois voyelles supplémentaires (=äåö=). Parmi les 26 caractères latins, certains sont majoritairement utilisés dans des mots d'emprunt (=bcfgqwxz=). De plus, =å= est un emprunt de l'alphabet suédois et n'est présent que dans des noms propres.

Les groupes formés dans la table [[finnishgrp]] sont les consonnes et les voyelles. Une analyse de la table [[finnishrep]] suggère que les distinctions entre les consonnes et les voyelles sont fortement prononcées, hormis pour les lettres =c=, =g= et =s=.

#+BEGIN_SRC sh :tangle bestwikifinnish.sh :exports results :results replace drawer :shebang "#!/usr/bin/env bash" :noweb yes
  pattern='wikifinnish_execution_'
  <<extractresults>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
#+CAPTION: Probabilités d'observation - Wikipédia finnois
#+NAME: finnishrep
| Caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| a                 | $21.880$   | $0.050$    |
| ä                 | $4.969$    | $0.007$    |
| å                 | $0.000$    | $0.000$    |
| b                 | $0.000$    | $0.737$    |
| c                 | $0.165$    | $0.200$    |
| d                 | $0.000$    | $2.595$    |
| e                 | $13.655$   | $0.000$    |
| f                 | $0.003$    | $0.355$    |
| g                 | $0.189$    | $0.694$    |
| h                 | $0.000$    | $2.929$    |
| i                 | $17.054$   | $0.000$    |
| j                 | $0.000$    | $4.033$    |
| k                 | $0.000$    | $9.685$    |
| l                 | $0.000$    | $10.978$   |
| m                 | $0.000$    | $6.286$    |
| n                 | $0.000$    | $15.539$   |
| o                 | $9.861$    | $0.000$    |
| ö                 | $0.800$    | $0.000$    |
| p                 | $0.000$    | $3.287$    |
| q                 | $0.000$    | $0.004$    |
| r                 | $0.000$    | $5.565$    |
| s                 | $0.289$    | $12.416$   |
| t                 | $0.000$    | $15.069$   |
| u                 | $10.072$   | $0.000$    |
| v                 | $0.000$    | $3.740$    |
| w                 | $0.000$    | $0.173$    |
| x                 | $0.000$    | $0.045$    |
| y                 | $2.697$    | $0.000$    |
| z                 | $0.000$    | $0.115$    |
| \textvisiblespace | $18.365$   | $5.495$    | 



#+CAPTION: Groupes formés - Wikipédia finnois
#+NAME: finnishgrp
| Groupe 1                          | Groupe 2                                | Hors groupes |
|-----------------------------------|-----------------------------------------|--------------|
| a ä e i o ö u y \textvisiblespace | b c d f g h j k l m n p q r s t v w x z | å            |
:END:


#+BEGIN_SRC sh :shebang "#!/usr/bin/env bash" :exports none :results replace drawer output
  pattern='wikifinnish_execution_'
  well_formed=$(cat $pattern* | grep -c "\\textvisiblespace,  a,  ä,  e,  i,  o,  ö,  u,  y }")
  total=$(ls -1  $pattern* | wc -l)
  percentage=$(bc <<<"scale=3;$well_formed/$total")
  
  echo "$x : $percentage ($well_formed / $total)"
#+END_SRC

#+RESULTS:
:RESULTS:
 : .600 (30 / 50)
:END:


* Discussion                                                         :export:
Il semble y avoir en anglais, comme en français et en finnois, une distinction statistique entre consonnes et voyelles, distinction pouvant être mise en évidence à l'aide de modèles de Markov.

Ainsi, ces trois langages montrent une relation entre les groupes formés par des modèles de Markov et des caractéristiques linguistiques.
En faisant l'expérience avec un vaste échantillon de langues écrites, il serait possible de constater empiriquement si cette relation est une propriété fondamentale des languages naturels.

Il serait également intéressant de répéter cette expérience en utilisant des modèles de Markov à trois, quatre - ou plus - états.
L'expérience présentée ne considérait que des caractères individuels ; un autre paramètre à faire varier est le nombre de caractères constituant une observation.
Ces variantes nécessiteraient une plus grande puissance de calcul.
Ainsi, le temps d'apprentissage pourrait devenir un problème.
Il serait mieux pour cela d'utiliser une bibliothèque externe plutôt que l'implémentation naïve utilisée ici.



* Sources                                                            :export:
:PROPERTIES:
:UNNUMBERED: t
:END:
\addcontentsline{toc}{chapter}{Sources}
Stamp, Mark. (2018). A Revealing Introduction to Hidden Markov Models. https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf.

* Testing scripts

#+BEGIN_SRC sh :tangle test_english.sh :shebang "#!/usr/bin/env bash"
  echo "testing on brown corpus"
  ./brownextract.py > /dev/null
  echo "predefined matrices groups"
  ./brownmarvin.py | tail -n 1
  echo "procedurally generated groups"
  ./brownrandom.py | tail -n 1
#+END_SRC

#+BEGIN_SRC sh :tangle test_french.sh :shebang "#!/usr/bin/env bash" :noweb yes
  echo "testing on est républicain corpus"
  ./repextract.py
  pattern='.french_results'
  ./repfrench.py > $pattern
  <<extractresults>>
#+END_SRC

#+BEGIN_SRC sh :tangle test_finnish.sh :shebang "#!/usr/bin/env bash" :noweb yes
  echo "testing on finnish wikipedia corpus"

  # The wikipedia dump is too heavy to put on github or to download separately
  # ./wikifiextract.sh

  pattern='.finnish_results'
  ./wikifinnish.py > $pattern
  <<extractresults>>
#+END_SRC

#+BEGIN_SRC sh :tangle test_all.sh :shebang "#!/usr/bin/env bash"
  ./test_english.sh
  echo
  ./test_french.sh
  echo
  ./test_finnish.sh
#+END_SRC

