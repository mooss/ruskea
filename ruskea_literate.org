#+TITLE: Distanciel modèles de Markov cachés
#+AUTHOR: Félix Jamet
#+OPTIONS: toc:2
#+LANGUAGE: fr
#+PROPERTY: header-args:ipython :session markexec :results silent :tangle markov.py :eval no-export :noweb yes

* Consignes

L’expérimentation présentée dans l’article est (à mon avis) passionnante. Et il serait intéressant de la reproduire sur une autre langue, par exemple la langue française. Pour cela vous devrez:

 - Trouver un corpus en langue française, de taille raisonnable (prendre en référence ce qui est proposé dans l’article)
 - Nettoyer ce corpus pour ne garder que les 26 lettres de l’alphabet et les espaces
 - Utiliser un EM/Baum Welch déjà implémenté (par exemple dans les bibliothèques des langages de programmation) ou utilisez le pseudo-code fourni dans l’algorithme pour réimplémenter votre Baum Welch, pour apprendre les paramètres de votre HMM.
 - Dessinez le HMM (si vous avez utilisé une bibliothèque) et analysez les résultats : à deux classes a-t-on bien les voyelles et les consonnes?

Si vous êtes plus de 2 à faire le choix 4, il est demandé de regarder d’autres langues, en particulier l’Espagnol et l’Allemand. On peut prendre comme base : n étudiants : n-1 langues.

* Quelques définitions
 - États :: ce que l'on cherche à prédir.
 - Observations :: informations supplémentaires que l'on va utiliser afin de prédire les états.

* Notations

#+CAPTION: Notation des modèles de Markov
#+NAME: tbl.notations
| symbole                                                                  | signification                        |
|--------------------------------------------------------------------------+--------------------------------------|
| $A$                                                                      | matrice des transitions              |
| $B$                                                                      | matrice des observations             |
| $\pi$                                                                    | distribution initiale des états      |
|--------------------------------------------------------------------------+--------------------------------------|
| $N$                                                                      | nombre d'états dans le modèle        |
| $Q = \{q_0, q_1, \dots, \q_{N-1}\}$                                      | ensemble des états                   |
|--------------------------------------------------------------------------+--------------------------------------|
| $M$                                                                      | nombres de symboles d'observation    |
| $V = \{0, 1, \dots, M-1\}$                                               | ensemble des observations possibles  |
| $T$                                                                      | longueur de la chaine d'observations |
| $\mathcal{O} = (\mathcal{O}_0, \mathcal{O}_1, \dots, \mathcal{O}_{T-1})$ | chaine d'observations                |

La table [[tbl.notations]] est séparée en trois parties.
La première rassemble ce qui définit un modèle de Markov, la deuxième est constituée de caractéristiques calculées et la dernière partie concerne les observations.

La matrice des transitions est notée $A = \{a_{i,j}\}$, avec
$a_{i,j} = P(\text{ état } q_j \text{ au temps } t+1 | \text{ état } q_i \text{ au temps } t)$.
Ainsi, si on envisage de manipuler la matrice $A$ comme un tableau de tableaux, on a $A[i][j] = a_{i,j}$


$A_{i,j}$ correspond à la probabilité d'être dans l'état $q_j$ sachant qu'on était avant dans l'état $q_i$.
Autrement dit, la probabilité de passer dans l'état $q_j$ si l'on est dans l'état $q_i$.
On remarque que les probabilités des transitions sont indépendantes du temps $t$.

La matrice des observations est notée $B = \{b_j(k)\}$, avec
$$b_j(k) = P(\text{observation } k \text{ au temps } t | \text{ état } q_j \text{ au temps } t)$$
$b_j(k)$ est donc la probabilité d'observer $k$ en étant dans l'état $q_j$. Bien que surprenante, la notation $b_j(k)$ semble être standard dans le domaine des modèles de Markov.

$\pi$ est la distribution initiale des états, c'est à dire la probabilité de démarer dans chacun des état. Il s'agit donc là encore d'une matrice stochastique.

Un modèle de Markov caché (MMC) est défini par $A$, $B$ et $\pi$, et se note typiquement $$\lambda = (A, B, \pi)$$

* Problèmes pour lesquels les MMC sont utiles
Il existe trois problèmes particuliers qui peuvent être résolus à l'aide des modèles de Markov cachés.

** Problème 1
Étant donné un MMC et une chaine d'observations, trouver la probabilité de cette chaine selon ce modèle. Autrement dit, étant donné le MMC $\lambda = (A, B, \pi)$ et la chaine d'observation 
$\mathcal{O} = (\mathcal{O}_0, \mathcal{O}_1, \dots, \mathcal{O}_{T-1})$
, trouver $P(\mathcal{O} | \lambda )$.

Cette probabilité correspond à la somme des probabilités d'observer $\mathcal{O}$ sur tous les arrangements avec répétition de longueur $T$ des états de $\lambda$.
Étant donné que cette méthode revient à faire une somme sur $N^T$ éléments, on développe l'intuition qu'elle n'est pas viable.

** Problème 2
Étant donné un MMC et une chaine d'observation, trouver l'enchainement d'états optimal correspondant.

Les enchainements optimaux d'états trouvés par la programmation dynamique et par les modèles de Markov cachés sont susceptibles de différer. En effet, la programmation dynamique permettra de trouver l'enchainement d'états ayant la plus haute probabilité, tandis que les MMC vont trouver l'enchainement dont les états ont la plus grande probabilité d'être individuelement corrects.
Autrement dit, les MMC vont permettre de maximiser le nombre d'états corrects.

** Problème 3
Étant donné une chaine d'observation, un nombre d'états et un nombre de symboles, trouver le MMC maximisant la probabilité de cette chaine d'observation, autrement dit, entrainer un HMM pour le faire correspondre aux observations.

* Réimplémentation de Baum-Welch
:PROPERTIES:
:header-args:ipython: :session markexec :results silent :tangle markov.py
:END:
** Modèles de Markov
 
#+BEGIN_SRC ipython :results silent
  import math
  import random
  from numpy import zeros, full, array
  from copy import deepcopy

  def stochastic_variation(mat, epsilon):
      """Slightly changes the values of a matrix while making sure that the sum of the rows are kept the same.

      Parameters
      ----------
      mat : np.matrix
          Matrix to change.

      epsilon : float
          Maximal variation.
      """
      random.seed()
      for row in mat:
          delta = 0
          for i in range(0, len(row)):
              # if delta > epsilon / 2:
              #     nextvariation = random.uniform(-epsilon, 0)
              # elif delta < -epsilon / 2:
              #     nextvariation = random.uniform(0, epsilon)
              # else:
              #     nextvariation = random.uniform(-epsilon, epsilon)
              if random.uniform(0, 1) >= .5:
                  row[i] += random.uniform(*epsilon) #nextvariation
              else:
                  row[i] -= random.uniform(*epsilon)

              if row[i] < 0:
                  row[i] = -row[i]
                  # delta += nextvariation

          factor = 1/sum(row)
          for i in range(0, len(row)):
              row[i] *= factor
          #     nextvalue = random.gauss(row[i], epsilon)
          #     delta += nextvalue - row[i]
          #     row[i] = nextvalue
          # meandelta = delta/len(row)
          # for i in range(0, len(row)):
          #     row[i] -= meandelta


  def prob_matrix(M, p_range):
      try:
          for i in range(M.shape[0]):
              for j in range(M.shape[1]):
                  if random.uniform(0, 1) >= .5:
                      M[i][j] += random.uniform(p_range[0], p_range[1])
                  else:
                      M[i][j] -= random.uniform(p_range[0], p_range[1])
          for i in range(M.shape[0]):
              factor = M[i].sum()
              for j in range(M.shape[1]):
                  M[i][j] *= 1/factor
      except:
          for j in range(M.shape[0]):
              if random.uniform(0, 1) >= .5:
                  M[j] += random.uniform(p_range[0], p_range[1])
              else:
                  M[j] -= random.uniform(p_range[0], p_range[1])
          factor = M.sum()
          for j in range(M.shape[0]):
              M[j] *= 1/factor
      return M


  class markovmodel(object):
      def fromscratch(N, M):
          """Create a Markov model from scratch with the following matrices dimensions:
           - A is NxN
           - B is NxM
           - PI is 1xN

          Parameters
          ----------
          N : int

          M : int

          Returns
          -------
          out : The corresponding Markov model
          """
          inverseN = 1 / N
          inverseM = 1 / M

          transition = full((N, N), inverseN)
          observation = full((N, M), inverseM)
          initial = full((1, N), inverseN)

          # prob_matrix(transition, (0.001, 0.005))
          # prob_matrix(observation, (0.02, 0.025))
          stochastic_variation(transition, (0.000, 0.005))
          stochastic_variation(observation, (0.02, 0.025))
          stochastic_variation(initial, (0.001, 0.005))

          return markovmodel(transition, observation, initial)

      def __init__(self,
                   transition_matrix,
                   observation_matrix,
                   initial_state_distribution,
                   rel_tol=1e-9):
          """Create a markov model.

          Parameters
          ----------
          transition_matrix : np.matrix
              NxN matrix containing the state transitions probabilities.

          observation_matrix : np.matrix
              NxM matrix containing the observation probabilities.

          initial_state_distribution : np.matrix
              1xN matrix containing the initial state distribution
          """
          self.transition_matrix = transition_matrix
          self.observation_matrix = observation_matrix
          self.initial_state_distribution = initial_state_distribution
          self.rel_tol = rel_tol
          self.ensure_dimensional_validity()
          self.ensure_row_stochasticity()

          self.ndim = transition_matrix.shape[0]
          self.mdim = observation_matrix.shape[1]

      def __str__(self):
          return '\n'.join((
              'transition:',
              str(self.transition_matrix), '',
              'observation:',
              str(self.observation_matrix), '',
              'initial states:',
              str(self.initial_state_distribution)))

      def ensure_dimensional_validity(self):
          """Raises an exception if the matrices' dimensions are not right.
          """
          tr_rows, tr_columns = self.transition_matrix.shape
          ob_rows, _ = self.observation_matrix.shape
          in_rows, in_columns = self.initial_state_distribution.shape

          if not (tr_rows == tr_columns == ob_rows == in_columns):
              raise ValueError('The number of transition rows, transition columns, observation rows and initial state distribution columns is not the same')

          if in_rows != 1:
              raise ValueError("The initial state distribution matrix should have one and only one row")

      def ensure_row_stochasticity(self):
          """Raises an exception if the matrices are not row-stochastic.
          """
          def fullofones(iterable):
              return all(math.isclose(el, 1, rel_tol = self.rel_tol) for el in iterable)

          if not fullofones(self.transition_matrix.sum(axis=1)):
              raise ValueError("The transition matrix is not row stochastic")

          if not fullofones(self.observation_matrix.sum(axis=1)):
              raise ValueError("The observation matrix is not row stochastic")

          if not fullofones(self.initial_state_distribution.sum(axis=1)):
              raise ValueError("The initial_state_distribution matrix is not row stochastic")

      def getinitialstate(self, i):
          return self.initial_state_distribution[0,i]
#+END_SRC

*** Tests
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

**** Initialisation

#+BEGIN_SRC ipython :shebang "#!/usr/bin/env python3" :eval never :exports none
  from markov import *
  import np
#+END_SRC

**** Création /from scratch/
#+BEGIN_SRC ipython 
  markovtest = markovmodel.fromscratch(3, 4)
  print(markovtest.transition_matrix)
#+END_SRC

#+RESULTS:
: [[0.31821417 0.31306151 0.36872432]
:  [0.33979492 0.31437166 0.34583341]
:  [0.32128992 0.36485099 0.31385909]]

**** Exemple prédiction de température
Il s'agit ici de tester la création des chaines de markov en utilisant l'exemple de prédiction de température.

#+BEGIN_SRC ipython
  try:
      markovtemperature = markovmodel(
          np.matrix([[0.7, 0.3],
                     [0.4, 0.6]]),
          np.matrix([[0.1, 0.4, 0.5],
                     [0.7, 0.2, 0.1]]),
          np.matrix([[0.6, 0.4]])
      )
      print('transition:', markovtemperature.transition_matrix,
            'observation:', markovtemperature.observation_matrix,
            'initial states:', markovtemperature.initial_state_distribution,
            sep='\n')
  except Exception as e:
      print('construction failed:', str(e))
#+END_SRC

#+RESULTS:
: construction failed: name 'np' is not defined

** Forward

#+BEGIN_SRC ipython :results output silent

  def alpha_pass(markov, observations):
      """Implementation of the forward algorithm to compute the alpha_t values.

      Parameters
      ----------
      markov : markovchain

      observations : iterable

      Returns
      -------
      out : np.array
          The alpha_t values.
      """
      alpha = zeros(shape=(len(observations), markov.ndim))
      scale_factors = zeros(shape=(len(observations)))
    
      # alpha_zero initialization

      for i in range(0, markov.ndim):
          alpha[0, i] = markov.getinitialstate(i) * markov.observation_matrix[i, 0]
          scale_factors[0] += alpha[0, i]

      scale_factors[0] = 1 /scale_factors[0]
    
      for i in range(0, markov.ndim):
          alpha[0, i] *= scale_factors[0]

      # alpha_t computation
      for t in range(1, len(observations)):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  alpha[t, i] += alpha[t - 1, j] * markov.transition_matrix[j, i]
              alpha[t, i] *= markov.observation_matrix[i, observations[t]]
              scale_factors[t] += alpha[t, i]

          # scale alpha
          scale_factors[t] = 1 / scale_factors[t]
          for i in range(0, markov.ndim):
              alpha[t, i] *= scale_factors[t]

      return (alpha, scale_factors)
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:
#+BEGIN_SRC ipython
  observations = [0, 1, 0, 2]
  alpha_matrix, scales = alpha_pass(markovtemperature, observations)
  print(alpha_matrix)
  print(scales)
#+END_SRC

#+RESULTS:
: [[0.17647059 0.82352941]
:  [0.62348178 0.37651822]
:  [0.16880093 0.83119907]
:  [0.8039794  0.1960206 ]]
: [2.94117647 3.44129555 2.87543655 3.56816483]

**** backup
#+RESULTS:
: [[0.17647059 0.82352941]
:  [0.62348178 0.37651822]
:  [0.16880093 0.83119907]
:  [0.8039794  0.1960206 ]]

** Backward

#+BEGIN_SRC ipython :results output silent
  def beta_pass(markov, observations, scale_factors):
      """

      Parameters
      ----------
      markov : 

      observations : 

      Returns
      -------
      out : 

      """
      beta = zeros(shape=(len(observations), markov.ndim))

      # all elements of the last column take the last scale factor as value
      # np.vectorize(lambda _: scale_factors[-1])(beta.transpose()[-1])
      # for line in beta:
      #     line[-1] = scale_factors[-1]
      for i in range(0, markov.ndim):
          beta[-1, i] = scale_factors[-1]

      for t in reversed(range(0, len(observations) - 1)):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  beta[t, i] += markov.transition_matrix[i, j] * markov.observation_matrix[j, observations[t+1]] * beta[t + 1, j]

              # scale beta
              beta[t, i] *= scale_factors[t]

      return beta
#+END_SRC

*** Tests
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  beta_matrix = beta_pass(markovtemperature, observations, scales)
  print(beta_matrix)
#+END_SRC

#+RESULTS:
: [[3.1361635  2.89939354]
:  [2.86699344 4.39229044]
:  [3.898812   2.66760821]
:  [3.56816483 3.56816483]]

** Gamma et di-gamma

#+BEGIN_SRC ipython :results silent
  def gamma_digamma_pass(markov, observations, alpha, beta):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      alpha : 
    
      beta : 
    
      Returns
      -------
      out : 
    
      """
      digamma = zeros(shape=(len(observations), markov.ndim, markov.ndim))
      gamma = zeros(shape=(len(observations), markov.ndim))

      for t in range(0, len(observations) - 1):
          for i in range(0, markov.ndim):
              for j in range(0, markov.ndim):
                  digamma[t, i, j] = alpha[t, i] * markov.transition_matrix[i, j] * markov.observation_matrix[j, observations[t + 1]] * beta[t + 1, j]
                  gamma[t, i] += digamma[t, i, j]

      # special case for the last gammas
      for i in range(0, markov.ndim - 1):
          gamma[-1, i] = alpha[-1, i]

      return (gamma, digamma)
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  gamma, digamma = gamma_digamma_pass(
      markovtemperature,
      observations,
      alpha_matrix,
      beta_matrix
  )
  print(gamma, '\n\n\n', digamma, sep='')
#+END_SRC

#+RESULTS:
#+begin_example
[[0.18816981 0.81183019]
 [0.51943175 0.48056825]
 [0.22887763 0.77112237]
 [0.8039794  0.        ]]


[[[0.14166321 0.0465066 ]
  [0.37776855 0.43406164]]

 [[0.17015868 0.34927307]
  [0.05871895 0.4218493 ]]

 [[0.21080834 0.01806929]
  [0.59317106 0.17795132]]

 [[0.         0.        ]
  [0.         0.        ]]]
#+end_example


*** =greek_pass=
La fonction =greek_pass= fait office de sucre syntaxique, pour faire toutes les passes définies précédemment en récupérant seulement ce qui nous intéresse, à savoir les gammas et di-gammas.

#+BEGIN_SRC ipython 
  def greek_pass(markov, observations):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      Returns
      -------
      out : 
    
      """
      alpha, scale_factors = alpha_pass(markov, observations)
      beta = beta_pass(markov, observations, scale_factors)
      return (*gamma_digamma_pass(markov, observations, alpha, beta), scale_factors)
#+END_SRC

**** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  gamma2, digamma2, scale_factors = greek_pass(markovtemperature, observations)
  if not np.array_equal(gamma, gamma2) or not np.array_equal(digamma, digamma2):
      print('gammas or digammas from greek_pass and from gamma_digamma_pass differ')
  else:
      print('gammas and digammas from greek_pass and from gamma_digamma_pass are the same')

  if not np.array_equal(scales, scale_factors):
      print('the scale factors from alpha_pass et greek_pass differ')
  else:
      print('the scale factors from alpha_pass et greek_pass are the same')
#+END_SRC

#+RESULTS:
: gammas and digammas from greek_pass and from gamma_digamma_pass are the same
: the scale factors from alpha_pass et greek_pass are the same

** Réestimation

*** Distribution initiale des états

#+BEGIN_SRC ipython
  def reestimate_initial_state_distribution(markov, gamma):
      """Use previously-calculated gamma values to do a re-estimation of the initial state distribution.

      Parameters
      ----------
      markov : 
    
      gamma : 
    
      Returns
      -------
      out : 
      """
      for i in range(0, markov.ndim):
          markov.initial_state_distribution[0, i] = gamma[0, i]
#+END_SRC

*** Transitions

#+BEGIN_SRC ipython
  def reestimate_transition_matrix(markov, gamma, digamma):
      """


          Parameters
          ----------
          markov : 

          gamma : 

          digamma : 

          Returns
          -------
          out : 

      """
      for i in range(0, markov.ndim):
          for j in range(0, markov.ndim):
              gamma_acc, digamma_acc = 0, 0
              for t in range(0, len(gamma) - 1):
                  gamma_acc += gamma[t, i]
                  digamma_acc += digamma[t, i, j]
              markov.transition_matrix[i, j] = digamma_acc / gamma_acc

      markov.ensure_row_stochasticity()
#+END_SRC

*** Observations

#+BEGIN_SRC ipython
  def reestimate_observation_matrix(markov, observations, gamma):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      gamma : 
      """
      for i in range(0, markov.ndim):
          for j in range(0, markov.mdim):
              gamma_acc_observed, gamma_acc_all = 0, 0
              for t in range(0, len(observations)):
                  if observations[t] == j:
                      gamma_acc_observed += gamma[t, i]
                  gamma_acc_all += gamma[t, i]
              markov.observation_matrix[i, j] = gamma_acc_observed / gamma_acc_all
#+END_SRC

*** Probabilité de la chaine d'observation
La probabilité de la chaine d'observation selon le modèle de Markov est utilisé pour mesurer l'avancement de l'entrainement de ce modèle.

#+BEGIN_SRC ipython
  def log_observation_sequence_probability(scale_factors):
      """Compute the log of the observation's sequence probability according to a markov model, using the scales factors.

      Parameters
      ----------
      scale_factors : 

      Returns
      -------
      out : 
      """
      result = 0
      for i in range(0, len(scale_factors)):
          result += math.log(scale_factors[i])
      return -result

#+END_SRC

*** Modèle
On utilise les trois fonctions de réestimation précédentes pour réestimer le modèle dans sa globalité, à partir de la chaine des observations.

#+BEGIN_SRC ipython
  def reestimate_markov_model(markov, observations):
      """

      Parameters
      ----------
      markov : 
    
      observations : 
    
      Returns
      -------
      out : 
      """
      gamma, digamma, scale_factors = greek_pass(markov, observations)
      reestimate_initial_state_distribution(markov, gamma)
      reestimate_transition_matrix(markov, gamma, digamma)
      reestimate_observation_matrix(markov, observations, gamma)
      return log_observation_sequence_probability(scale_factors)
#+END_SRC

*** Boucle de réestimation
L'entrainement d'un modèle de markov se fait en répétant des réevaluations.
On arrête la boucle de réestimation lorsque un nombre pré-déterminé a été achevé ou lorsque la réestimation cesse d'apporter des améliorations par rapport à l'itération précédente.

#+BEGIN_SRC ipython
  def train_markov_model(markov, observations, max_iterations=200):
      """

      Parameters
      ----------
      markov : 

      observations : 

      max_iterations : 

      Returns
      -------
      out : 
      """
      _, scale_factors = alpha_pass(markov, observations)
      bestlogprob = log_observation_sequence_probability(scale_factors)
      bestmodel = deepcopy(markov)

      for i in range(1, max_iterations):
          logprob = reestimate_markov_model(markov, observations)
          markov.ensure_row_stochasticity()
          if logprob > bestlogprob:
              bestmodel = deepcopy(markov)
              bestlogprob = logprob

      markov = deepcopy(bestmodel)
      return bestlogprob
#+END_SRC

L'initialisation des matrices d'un modèle de Markov est délicate et il est difficile de garantir que des matrices initialisées aléatoirement vont produire un bon résultat.
D'où l'idée d'initialiser aléatoirement $X$ modèles, de les entrainer $Y$ fois, et de finir l'entrainement du modèle le plus prometteur.

#+BEGIN_SRC ipython
  def train_best_markov_model(N, M, observations, nb_candidates, train_iter, max_iter):
      bestmodel = markovmodel.fromscratch(N, M)
      bestprob = train_markov_model(bestmodel, observations, train_iter)

      for i in range(0, nb_candidates - 1):
          candidate = markovmodel.fromscratch(N, M)
          candidateprob = train_markov_model(candidate, observations, train_iter)

          if candidateprob > bestprob:
              bestprob = candidateprob
              bestmodel = deepcopy(candidate)

      print(bestprob)
      print(bestmodel)
      train_markov_model(bestmodel, observations, max_iter - train_iter)
      return bestmodel
#+END_SRC

*** Test
:PROPERTIES:
:header-args:ipython: :tangle markov_tests.py :session markexec :results output replace
:END:

#+BEGIN_SRC ipython
  from copy import deepcopy
  markov_copy = deepcopy(markovtemperature)
  print(markov_copy)
  train_markov_model(markov_copy, observations, 10)
  print(markov_copy)
#+END_SRC

#+RESULTS:
#+begin_example
transition:
[[0.7 0.3]
 [0.4 0.6]]

observation:
[[0.1 0.4 0.5]
 [0.7 0.2 0.1]]

initial states:
[[0.6 0.4]]
the model stopped improving at iteration 9
transition:
[[3.80741949e-287 1.00000000e+000]
 [1.00000000e+000 0.00000000e+000]]

observation:
[[9.52278575e-288 5.00000000e-001 5.00000000e-001]
 [1.00000000e+000 0.00000000e+000 0.00000000e+000]]

initial states:
[[1.69480811e-290 1.00000000e+000]]
#+end_example



* Analyse de texte assistée par un modèle de Markov caché

#+BEGIN_SRC ipython
  def map_el_to_int(iterable, alphabet):
      """Map all the elements of an iterable to their index in an alphabet.
      If an element is not in the alphabet, it will be ignored.

      Parameters
      ----------
      iterable : iterable
          The iterable to map.

      alphabet : str
          The letters to keep.

      Returns
      -------
      out : list of int
          The list containing the index of each character in the input string.
      """
      indexation = {letter: index for index, letter in enumerate(alphabet)}
      return (indexation[char] for char in iterable if char in alphabet)

  def markov_alphabetical_analysis(markov, alphabet):
      observation_scores = [[letter,
                             ,*(markov.observation_matrix[state, index]
                                for state in range(0, markov.ndim))]
                            for index, letter in enumerate(alphabet)]

      letter_groups = [list() for _ in range(0, markov.ndim)]
      ungroupables = []

      for letterindex, letter in enumerate(alphabet):
          maxindex = 0
          for state in range(1, markov.ndim):
              if markov.observation_matrix[state, letterindex] >\
                 markov.observation_matrix[maxindex, letterindex]:
                  maxindex = state
              if markov.observation_matrix[maxindex, letterindex] == 0:
                  ungroupables.append(letter)
              else:
                  letter_groups[maxindex].append(letter)

      return observation_scores, letter_groups, ungroupables

#+END_SRC

* noweb
:PROPERTIES:
:header-args:ipython: :tangle no :session none :results silent :eval never
:END:

** corpuses
#+NAME: browncorpus
#+BEGIN_SRC ipython
  with open('brown50000.txt', 'r') as brownfile:
      corpus = brownfile.read().replace('\n', '')
#+END_SRC

#+NAME: repcorpus
#+BEGIN_SRC ipython
  with open('1999-05-17.txt', 'r') as repfile:
      corpus = repfile.read().replace('\n', '')
#+END_SRC

** Alphabets

#+NAME: latinalphabet
#+BEGIN_SRC ipython
  alphabet = ' abcdefghijklmnopqrstuvwxyz'
#+END_SRC

#+NAME: frenchalphabet
#+BEGIN_SRC ipython
  alphabet = ' aàâæbcçdeéèêëfghiîïjklmnoôœpqrstuùûüvwxyÿz'
#+END_SRC

** Observations

#+NAME: rawObservations
#+BEGIN_SRC ipython
  observations = list(islice(
      map_el_to_int(corpus, alphabet),
      0, 50000))
#+END_SRC

#+NAME: observationsNoSpecials
#+BEGIN_SRC ipython
  def translate(iterable, translation_table):
      for el in iterable:
          if el in translation_table:
              for tr in translation_table[el]:
                  yield tr
          else:
              yield el

  translations = {'à': 'a',
                  'â': 'a',
                  'æ': 'ae',
                  'ç': 'c',
                  'é': 'e',
                  'è': 'e',
                  'ê': 'e',
                  'ë': 'e',
                  'î': 'i',
                  'ï': 'i',
                  'ô': 'o',
                  'œ': 'oe',
                  'ù': 'u',
                  'û': 'u',
                  'ü': 'u',
                  'ÿ': 'y',
                  '\'': ' ',
                  '-': ' '}

  observations = list(islice(
      map_el_to_int(translate(corpus, translations), alphabet),
      0, 50000))
#+END_SRC

** Autres

#+NAME: markovimport
#+BEGIN_SRC ipython
  from itertools import islice
  from markov import *
#+END_SRC

#+NAME: trainfromscratch
#+BEGIN_SRC ipython
  model = train_best_markov_model(
      2, len(alphabet),
      observations,
      20,
      4,
      100)
#+END_SRC

#+NAME: print_probas
#+BEGIN_SRC ipython
  _, scale_factors = alpha_pass(model, observations)
  print('score', log_observation_sequence_probability(scale_factors))
#+END_SRC


#+NAME: markov_report
#+BEGIN_SRC ipython
  def latexify(char):
      if char == ' ':
          return '\\textvisiblespace'
      return char


  scoretable, groups, ungroupables = markov_alphabetical_analysis(model, alphabet)
  scoretable = [[latexify(line[0]),
                 ,*('${:.3f}$'.format(probas * 100) for probas in line[1:])]
                for line in scoretable]
  scoretable.insert(0, ['caractère', 'État 1 (%)', 'État 2 (%)'])
  print('#+ATTR_LATEX: :align l l l\n',
        '#+CAPTION: répartition des caractères', sep='')
  try:
      print('#+NAME:', name + 'rep')
  except NameError:
      pass
  print(orgmodetable(scoretable, header=True), '\n\n\n')

  groupstable = [['{ ' + ',  '.join((latexify(char) for char in group)) + ' }'
                    for group in groups] ]
  groupstable.insert(0, ['Groupe 1', 'Groupe 2'])

  if len(ungroupables) > 0:
      groupstable[0].insert(
          len(ungroupables), 'Hors groupes')
      groupstable[1].insert(
          len(ungroupables), '{ ' + ', '.join(latexify(char) for char in ungroupables) + ' }')

  print('#+CAPTION: groupes formés')
  try:
      print('#+NAME:', name + 'grp')
  except NameError:
      pass
  print(orgmodetable(groupstable, header=True))
#+END_SRC


* Introduction                                                       :export:
L'expérience de "Marvin le martien" (Stamp 2018) montre qu'il est possible d'extraire des caractéristiques linguistiques à partir d'un corpus de petite taille (50000 caractères), et ce sans connaissances préalables sur la langue du corpus.
Cette expérience consiste à entrainer des modèles de Markov cachés comprenant deux états sur le corpus.
Les deux états ainsi formés regroupent d'une part les consonnes et d'autre part les voyelles.

Nous allons dans un premier temps reproduire cette expérience sur le corpus évoqué dans Stamp (2018), puis nous allons mener une expérience similaire sur un corpus en langue française.

Le choix a été fait d'implémenter en python l'algorithme d'entrainement d'un modèle de markov caché. Cette implémentation, de même que ce rapport sont disponibles sur github à l'adresse suivante : https://github.com/mooss/ruskea.

* Reproduction de l'expérience sur le /Brown corpus/                 :export:

Cette section décrit les efforts fait pour reproduire l'expérience de "Marvin le martien" sur le /Brown corpus/.
Dans un premier temps la méthode utilisée pour extraire les 50000 premiers caractères du /Brown corpus/ va être détaillée.
Ensuite, une reproduction de l'expérience va être effectuée en utilisant les matrices proposées dans (Stamp 2018).
Finalement, l'expérience va être reproduite en initialisant les matrices procéduralement.
** Extraction des 50 000 premiers caractères du /Brown corpus/

La première étape est d'extraire les caractères nous intéressant depuis le /Brown corpus/.
En effet, le /Brown corpus/ est distribué avec les annotations intégrées et il faut donc les supprimer.

La bibliothèque NTLK est utilisée pour télécharger le corpus.
Les 50000 premiers caractères de ce corpus sont écrits dans le fichier =brown50000.txt=, en utilisant le script =brownextract.py= :
#+BEGIN_SRC ipython :session brownextract :results silent :tangle brownextract.py :eval never :shebang "#!/usr/bin/env python3"
  import nltk
  nltk.download('brown')
  nltk.download('nonbreaking_prefixes')
  nltk.download('perluniprops')
  from nltk.corpus import brown
  from nltk.tokenize.moses import MosesDetokenizer

  mdetok = MosesDetokenizer()

  def remove_brown_annotations(sentence):
      return mdetok.detokenize(
          ' '.join(sent).replace('``', '"')\
          .replace("''", '"')\
          .replace('`', "'").split(),
          return_str=True)


  maxnbchar = 50000
  currentnbchar = 0
  charbuffer = []

  alphabet = 'abcdefghijklmnopqrstuvwxyz '

  for sent in brown.sents():
      for char in remove_brown_annotations(sent):
          if currentnbchar < maxnbchar and char in alphabet:
              charbuffer.append(char)
              currentnbchar += 1

  output = 'brown50000.txt'
  with open(output, "w") as text_file:
      text_file.write(''.join(charbuffer))

#+END_SRC

** Matrices prédéfinies
:PROPERTIES:
:header-args:ipython: :tangle brownmarvin.py :session brownmarvin_exec :results output replace drawer
:END:
Les matrices de transitions, observations, et des états initiaux sont initialisées selon les valeurs fournies dans l'article de Mark Stamp.

#+BEGIN_SRC ipython :exports code :shebang "#!/usr/bin/env python3" :noweb yes :results silent
  from numpy import array
  from markov import *

  marvin_transition = array([[0.47468, 0.52532],
                             [0.51656, 0.48344]])
  marvin_observation = array(
      [[0.03688, 0.03735, 0.03408, 0.03455, 0.03828, 0.03782, 0.03922, 0.03688, 0.03408, 0.03875, 0.04062, 0.03735, 0.03968, 0.03548, 0.03735, 0.04062, 0.03595, 0.03641, 0.03408, 0.04062, 0.03548, 0.03922, 0.04062, 0.03455, 0.03595, 0.03408, 0.03408],
       [0.03397, 0.03909, 0.03537, 0.03537, 0.03909, 0.03583, 0.03630, 0.04048, 0.03537, 0.03816, 0.03909, 0.03490, 0.03723, 0.03537, 0.03909, 0.03397, 0.03397, 0.03816, 0.03676, 0.04048, 0.03443, 0.03537, 0.03955, 0.03816, 0.03723, 0.03769, 0.03955]]
  )
  marvin_initial = array([[0.51316, 0.48684]])

  <<browncorpus>>

  <<latinalphabet>>

  model = markovmodel(marvin_transition, marvin_observation, marvin_initial, rel_tol=1e-3)

  train_markov_model(model,
                     list(map_el_to_int(corpus, alphabet)),
                     max_iterations=100)

#+END_SRC

Une tolérence relative de 1e^{-3} est appliquée à la construction du modèle pour vérifier la stochasticité des matrice. Sans cette tolérance élevé, l'étape de vérification de la stochasticité des matrices échoue.

Les valeurs ont été copiées telles quelles depuis l'article. Il est probables que ces valeurs aient été arrondies par l'auteur de l'article, d'où la nécessité d'assouplir le test de stochasticité.

*** Résultats
Les résultats sont synthétisés dans les tables [[marvinrep]] et [[marvingrp]].

La table [[marvinrep]] correspond à la transposée de la matrice d'observation du modèle de Markov entrainé, avec comme information supplémentaire en première colonne le caractère auquel correspondent les probabilités d'apparition des colonnes suivantes.
Les probabilités d'apparition sont rapportées sous forme de pourcentages, afin d'être plus lisibles.

La table [[marvingrp]] regroupe les caractères selon l'état pour lequel il ont la plus grande probabilité d'apparition.
Les résultats des autres expériences seront également présentés sous cette forme.

Les résultats obtenus sont les mêmes que ceux présentés dans (Stamp 2018), à savoir les voyelles (moins y) d'un côté et les consonnes (plus y) de l'autre.

#+BEGIN_SRC ipython :tangle no :exports results :noweb yes
  name = 'marvin'
  <<markov_report>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
#+CAPTION: répartition des caractères
#+NAME: marvinrep
| caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| \textvisiblespace | $28.066$   | $6.473$    |
| a                 | $14.255$   | $0.002$    |
| b                 | $0.000$    | $2.122$    |
| c                 | $0.069$    | $5.056$    |
| d                 | $0.000$    | $6.680$    |
| e                 | $22.567$   | $0.000$    |
| f                 | $0.000$    | $3.432$    |
| g                 | $0.445$    | $2.296$    |
| h                 | $0.050$    | $7.061$    |
| i                 | $12.772$   | $0.000$    |
| j                 | $0.000$    | $0.227$    |
| k                 | $0.293$    | $0.503$    |
| l                 | $0.006$    | $7.281$    |
| m                 | $0.000$    | $3.724$    |
| n                 | $0.000$    | $11.484$   |
| o                 | $13.769$   | $0.000$    |
| p                 | $0.186$    | $3.288$    |
| q                 | $0.000$    | $0.154$    |
| r                 | $0.000$    | $10.085$   |
| s                 | $0.015$    | $10.705$   |
| t                 | $2.039$    | $13.206$   |
| u                 | $4.653$    | $0.000$    |
| v                 | $0.000$    | $1.633$    |
| w                 | $0.000$    | $2.145$    |
| x                 | $0.000$    | $0.454$    |
| y                 | $0.815$    | $1.874$    |
| z                 | $0.000$    | $0.115$    | 



#+CAPTION: groupes formés
#+NAME: marvingrp
| Groupe 1                                  | Groupe 2                                                                              |
|-------------------------------------------|---------------------------------------------------------------------------------------|
| { \textvisiblespace,  a,  e,  i,  o,  u } | { b,  c,  d,  f,  g,  h,  j,  k,  l,  m,  n,  p,  q,  r,  s,  t,  v,  w,  x,  y,  z } |
:END:

** Matrices générées procéduralement
:PROPERTIES:
:header-args:ipython: :session brownrandomexec :results output replace drawer
:END:

L'article de Mark Stamp ne fournissait que peu de détails concernant l'initialisation des matrices de transition, observation et répartition initiale des états.
En effet, la seule indication donnée est d'initialiser les éléments de chaque ligne à environ $1/X$, $X$ étant le nombre d'éléments dans la ligne.

C'est un problème car en utilisant des matrices d'une forme similaire à celle utilisée dans la section précédentes, nous sommes susceptibles d'obtenir des résultat différents.

Après beaucoup d'essais infructeux, une solution satisfaisante a été trouvée.
La méthode =markovmodel.fromscratch= permettant d'initialiser un modèle de Markov est visible dans =markov.py=.

#+BEGIN_SRC ipython :exports code :noweb yes :tangle brownrandom.py :shebang "#!/usr/bin/env python3"
  <<markovimport>>

  <<browncorpus>>

  <<latinalphabet>>

  <<rawObservations>>

  <<trainfromscratch>>
#+END_SRC

#+RESULTS:
:RESULTS:
candidate prob: -141786.65054722823
best prob: -141786.65054722823
candidate prob: -141840.441896181
best prob: -141786.65054722823
candidate prob: -141842.98628147983
best prob: -141786.65054722823
candidate prob: -141841.1987589144
best prob: -141786.65054722823
candidate prob: -141842.53489207232
best prob: -141786.65054722823
candidate prob: -141803.5825126804
best prob: -141786.65054722823
candidate prob: -141838.55148309685
best prob: -141786.65054722823
candidate prob: -141803.49828079264
best prob: -141786.65054722823
candidate prob: -141837.1596564061
best prob: -141786.65054722823
candidate prob: -141834.68399909168
best prob: -141786.65054722823
[[' ', 0.2798627130811426, 0.06622028907197094], ['a', 0.14311235909888784, 6.334591627180954e-09], ['b', 3.1491112299604715e-23, 0.021141583024661098], ['c', 0.00031317343547325807, 0.05072900582585306], ['d', 2.419856920047442e-08, 0.06656532441063075], ['e', 0.2265352807577565, 1.4898193378347084e-19], ['f', 1.8624022048297262e-29, 0.034201872538083655], ['g', 0.0042286880299555055, 0.023093935305004115], ['h', 0.00027893077911133446, 0.07056142190476801], ['i', 0.12821093218053167, 4.859312199344216e-20], ['j', 3.2991262870933935e-52, 0.002259698185607062], ['k', 0.0029057387145665662, 0.005039547362859914], ['l', 8.404134654639013e-08, 0.07261666479569835], ['m', 2.480633796525442e-25, 0.037112670200899214], ['n', 1.9285805868712001e-22, 0.11444030811175099], ['o', 0.13821498435037421, 2.972082006305563e-10], ['p', 0.001600212730723405, 0.033005780134726444], ['q', 1.630790522879573e-43, 0.0015319987699029718], ['r', 1.5759874174671412e-28, 0.10049911930563549], ['s', 6.796346871407926e-06, 0.10681239558454744], ['t', 0.019685171093954828, 0.13231547801410035], ['u', 0.046713482466232935, 1.051338351913883e-09], ['v', 2.3835278616299776e-55, 0.016277486930218927], ['w', 3.0982618236773054e-29, 0.021371382840146662], ['x', 7.145086705958905e-35, 0.004519396371213874], ['y', 0.008331428694511797, 0.018535634551197774], ['z', 1.862892981874014e-70, 0.0011489990774272017]]
[[' ', 'a', 'e', 'i', 'o', 'u'], ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']]
:END:


#+BEGIN_SRC ipython :tangle no :exports results :noweb yes
  <<markov_report>>
#+END_SRC

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :align l l l
| caractère         | État 1 (%) | État 2 (%) |
|-------------------|------------|------------|
| \textvisiblespace | $0.020$    | $33.180$   |
| a                 | $0.008$    | $13.481$   |
| b                 | $2.239$    | $0.000$    |
| c                 | $5.402$    | $0.001$    |
| d                 | $7.050$    | $0.000$    |
| e                 | $0.057$    | $21.292$   |
| f                 | $3.622$    | $0.000$    |
| g                 | $2.730$    | $0.122$    |
| h                 | $6.055$    | $1.406$    |
| i                 | $0.000$    | $12.084$   |
| j                 | $0.239$    | $0.000$    |
| k                 | $0.537$    | $0.270$    |
| l                 | $7.436$    | $0.248$    |
| m                 | $3.931$    | $0.000$    |
| n                 | $12.121$   | $0.000$    |
| o                 | $0.001$    | $13.027$   |
| p                 | $3.591$    | $0.058$    |
| q                 | $0.162$    | $0.000$    |
| r                 | $10.644$   | $0.000$    |
| s                 | $11.307$   | $0.007$    |
| t                 | $15.514$   | $0.397$    |
| u                 | $0.000$    | $4.403$    |
| v                 | $1.724$    | $0.000$    |
| w                 | $2.264$    | $0.000$    |
| x                 | $0.479$    | $0.000$    |
| y                 | $2.745$    | $0.025$    |
| z                 | $0.122$    | $0.000$    | 



| Groupe 1                                                                              | Groupe 2                                  |
|---------------------------------------------------------------------------------------|-------------------------------------------|
| { b,  c,  d,  f,  g,  h,  j,  k,  l,  m,  n,  p,  q,  r,  s,  t,  v,  w,  x,  y,  z } | { \textvisiblespace,  a,  e,  i,  o,  u } |
:END:


* Est-Républicain                                                    :export:
Cette section s'appuie sur un corpus contenant des articles du journal l'Est Républicain, publiés en 1999.
Le corpus est disponible à l'adresse suivante : http://www.cnrtl.fr/corpus/estrepublicain/.

** Extraction du texte
Les articles sont contenus dans des fichiers =XML=. Le script suivant est utilisé pour récupérer le texte des articles en ignorant le balisage.

#+BEGIN_SRC ipython :tangle repextract.py :results silent :eval no-export :shebang "#!/usr/bin/env python3"
  import xml.etree.ElementTree as ET
  from itertools import chain

  root = ET.parse('1999-05-17.xml').getroot()
  articles = root.findall('./tei:text/tei:body/tei:div/tei:div/',
                          {'tei': 'http://www.tei-c.org/ns/1.0'})

  alphabet = ' aàâæbcçdeéèêëfghiîïjklmnoôœpqrstuùûüvwxyÿz'
  # print(list(root))
  # print(articles)

  def filterspaces(iterable):
      prevwasspace = True
      for char in iterable:
          if char == ' ':
              if not prevwasspace:
                  prevwasspace = True
                  yield char
          else:
              yield char
              prevwasspace = False


  charbuffer = (char
                for article in articles
                for paragraph in article.itertext()
                for char in paragraph.lower()
                if char in alphabet)

  with open('1999-05-17.txt', 'w') as output:
      output.write(''.join(filterspaces(charbuffer)))
#+END_SRC

Cette approche a ses limites, par exemple, il y a beaucoup de 'h' isolés à cause de la notation des heures (exemple : de 20h à 20h30). Par ailleurs la suppression de certain caractères spéciaux mène à des juxtapositions non désirables (exemple : saint-mihiel \textrightarrow saintmihiel, l'heure \textrightarrow lheure).

Il serait possible de créer des règles pour traiter ces cas particuliers. Cependant, ils semblent être statistiquement insignifiants, il n'est donc pas important de s'en soucier pour cette expérience.

** Analyse du texte brut
:PROPERTIES:
:header-args:ipython: :tangle repfrench.py :session repfrench :results output replace drawer
:END:

#+BEGIN_SRC ipython :shebang "#!/usr/bin/env python3" :eval never :exports none
  from markov import *
#+END_SRC

#+BEGIN_SRC ipython :exports code :shebang "#!/usr/bin/env python3" :noweb yes
  <<markovimport>>

  <<repcorpus>>

  <<frenchalphabet>>

  <<rawObservations>>

  <<trainfromscratch>>
#+END_SRC

#+RESULTS:
:RESULTS:
candidate prob: -143973.1283572361
best prob: -143960.7089248927
candidate prob: -143942.54735012856
best prob: -143942.54735012856
candidate prob: -81768.87271477211
best prob: -81768.87271477211
candidate prob: -143952.31804629278
best prob: -81768.87271477211
candidate prob: -140253.7572291471
best prob: -81768.87271477211
candidate prob: -5260.114374153069
best prob: -5260.114374153069
candidate prob: -142463.32283490506
best prob: -5260.114374153069
candidate prob: -143945.87970737182
best prob: -5260.114374153069
candidate prob: -45181.19021785969
best prob: -5260.114374153069
candidate prob: -143720.64082085402
best prob: -5260.114374153069
[[' ', 0.15693750391005312, 0.4296109657281298], ['a', 0.06918636096844555, 0.03533787163419111], ['à', 2.48678766398135e-15, 0.15156555845737188], ['â', 0.0003821299795589894, 0.0029574300283538185], ['æ', 0.0, 0.0], ['b', 0.009334752561243194, 3.1888945727930406e-10], ['c', 0.02847565517929709, 0.06648142352822134], ['ç', 0.0003950118015656476, 1.543736165286876e-26], ['d', 0.036819255518907336, 6.090355690590432e-08], ['e', 0.1226989787477217, 0.020103559575406754], ['é', 0.023596735025343155, 5.719450319583278e-07], ['è', 0.0031600944125251607, 4.851639977976246e-16], ['ê', 0.0012058254995161788, 1.600235441515676e-18], ['ë', 6.197691945324233e-05, 9.957430566697403e-06], ['f', 0.010087312422835587, 0.009368646164982442], ['g', 0.009584233711671738, -4.507345453440938e-20], ['h', 0.004273751174773885, 0.17389690180432546], ['i', 0.06058233630327822, 9.338232479004823e-16], ['î', 0.00024948113783093196, 2.7293951227937928e-21], ['ï', 0.0, 0.0], ['j', 0.0032639846166491854, 1.5256417235580305e-06], ['k', 0.0004365919912041333, 6.576304601372107e-24], ['l', 0.04971287318902626, 0.0404276466929838], ['m', 0.023472017050926847, -4.365411258875856e-21], ['n', 0.061705001423517376, 1.240089840504015e-22], ['o', 0.04571741850751834, -2.2738983494106243e-15], ['ô', 0.00040066139012646495, 0.0019620665486498583], ['œ', 0.00032901673078005367, 9.17558953298609e-05], ['p', 0.025023637530641157, 0.0017721174968767994], ['q', 0.005616786654535449, 0.0009649273540465112], ['r', 0.05948046127785821, 3.8927079594277817e-19], ['s', 0.06455324408634504, 8.28788327392991e-09], ['t', 0.05850332734751864, -1.3319054650701628e-08], ['u', 0.0459153162084879, 0.0055141031304701184], ['ù', 0.00022869104301168698, -1.6364900934927787e-28], ['û', 0.00018711085337042198, 7.033342337480367e-14], ['ü', 0.0, 0.0], ['v', 0.011746403572873211, -1.5746971142102233e-16], ['w', 0.00019811019063535913, 0.00024783798115344977], ['x', 0.00307455418445057, 0.05689732663650656], ['y', 0.002972983560010506, -2.1732264030536917e-11], ['ÿ', 0.0, 0.0], ['z', 0.00043041331648822824, 0.0027877501560632113]]
[['a', 'b', 'ç', 'd', 'e', 'é', 'è', 'ê', 'ë', 'f', 'g', 'i', 'î', 'j', 'k', 'l', 'm', 'n', 'o', 'œ', 'p', 'q', 'r', 's', 't', 'u', 'ù', 'û', 'v', 'y'], [' ', 'à', 'â', 'c', 'h', 'ô', 'w', 'x', 'z']]
:END:
 

#+BEGIN_SRC ipython :exports none :noweb yes
  <<print_probas>>
  <<markov_report>>
#+END_SRC


À première vue, les résultats ne sont pas concluants. Peut-être qu'un linguiste saura interpréter ces résultats, mais il est plus probable que l'utilisation d'un grand nombre de caractères peu fréquents perturbe l'entrainement du modèle.

** Analyse sans accents et ligatures
:PROPERTIES:
:header-args:ipython: :tangle repfrench_noaccent.py :session repfrench_noaccent :results output replace drawer
:END:

#+BEGIN_SRC ipython :exports code :noweb yes :shebang "#!/usr/bin/env python3"
  <<markovimport>>

  <<repcorpus>>

  <<latinalphabet>>

  <<observationsNoSpecials>>

  <<trainfromscratch>>
#+END_SRC

#+RESULTS:
:RESULTS:
candidate prob: -137931.02641606686
best prob: -137925.6412513305
candidate prob: -138041.7784606232
best prob: -137925.6412513305
candidate prob: -138044.73346667207
best prob: -137925.6412513305
candidate prob: -138036.2189776177
best prob: -137925.6412513305
candidate prob: -138036.95136939193
best prob: -137925.6412513305
candidate prob: -138014.5660628149
best prob: -137925.6412513305
candidate prob: -138041.18285977026
best prob: -137925.6412513305
candidate prob: -138038.7428735029
best prob: -137925.6412513305
candidate prob: -138033.43233621362
best prob: -137925.6412513305
candidate prob: -138026.15796260338
best prob: -137925.6412513305
[[' ', 0.3082149053176461, 6.942959849983107e-09], ['a', 0.122804848531593, 0.016336732820510954], ['b', 0.0012453673732095807, 0.018154048980993636], ['c', 0.0034801094300594888, 0.06206847288886445], ['d', 2.128478774524188e-20, 0.07743142483141699], ['e', 0.2692502882687037, 7.2320418001476235e-09], ['f', 9.639358663710727e-05, 0.02183404908882054], ['g', 1.208733975825522e-07, 0.020155636901870857], ['h', 1.1161790038167634e-09, 0.023434918896166505], ['i', 0.10782545331618615, 2.3615420189701233e-15], ['j', 3.9976552941270743e-54, 0.006864332974891336], ['k', 1.3064056179437364e-06, 0.0009166097243793307], ['l', 1.1518505520609156e-21, 0.10786184362456788], ['m', 1.6189403779781487e-23, 0.04936198680670307], ['n', 4.042428777763478e-09, 0.12972277187109535], ['o', 0.08246343216010521, 7.723039012634197e-26], ['p', 0.0038491708088197953, 0.04820698048942567], ['q', 6.002370913944218e-05, 0.011821156409917814], ['r', 1.2866292218907536e-13, 0.1250445369946814], ['s', 7.918670638327058e-15, 0.13571267231886416], ['t', 0.014607034455976102, 0.10566492531830633], ['u', 0.08249909703923589, 1.4215099318167195e-06], ['v', 3.0110013119311217e-36, 0.024702854336392552], ['w', 3.89745198810708e-38, 0.0004372186608211075], ['x', 0.0008271984809118574, 0.01021169834972511], ['y', 0.0027752450839274587, 0.002916923508644365], ['z', 3.0850132596018852e-31, 0.0011367685181348749]]
[[' ', 'a', 'e', 'i', 'o', 'u'], ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']]
:END:

 
# #+BEGIN_SRC ipython :exports results :tangle no :noweb yes
#   ## markov_report(repmarkov_latin, repalphabet_latin)
#   <<markovreport>>
# #+END_SRC

#+BEGIN_SRC ipython :exports none :noweb yes
  <<print_probas>>
  <<markov_report>>
#+END_SRC


* Sources
Stamp, Mark. (2018). A Revealing Introduction to Hidden Markov Models. https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf.

* 100 iter on brown backup
#+RESULTS:
#+begin_example
27 [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
50000 out of 50000
1.0000299999999998
1.00003
the model never stopped improving
CPU times: user 1min 59s, sys: 161 ms, total: 1min 59s
Wall time: 1min 59s
transition:
[[0.23368789 0.76631211]
 [0.70597863 0.29402137]]

observation:
[[2.80687985e-01 1.42581906e-01 1.40629293e-13 6.66524349e-04
  3.56911264e-06 2.25725373e-01 1.37666921e-17 4.42155954e-03
  4.87498731e-04 1.27752553e-01 6.73394223e-30 2.92496160e-03
  5.50924144e-05 2.54038203e-14 9.00794057e-12 1.37718752e-01
  1.83313919e-03 1.75675908e-23 5.22460779e-15 1.36925065e-04
  2.03105974e-02 4.65458472e-02 3.21539099e-30 1.30524222e-18
  6.21332760e-19 8.14771643e-03 4.60426291e-39]
 [6.47562560e-02 1.73259604e-05 2.12112202e-02 5.05695235e-02
  6.67813143e-02 5.46638241e-10 3.43145283e-02 2.29783808e-02
  7.06007667e-02 1.83269804e-12 2.26714128e-03 5.02886564e-03
  7.28051731e-02 3.72349136e-02 1.14817257e-01 1.92319303e-06
  3.28946287e-02 1.53704494e-03 1.00830148e-01 1.07044308e-01
  1.32110256e-01 5.77443034e-07 1.63311025e-02 2.14417769e-02
  4.53428257e-03 1.87385009e-02 1.15278370e-03]]

initial states:
[[1.00000000e+00 1.45406913e-11]]
#+end_example

* 200 iterations on brown
#+RESULTS:
#+begin_example
27 [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
50000 out of 50000
1.0000299999999998
1.00003
the model never stopped improving
CPU times: user 3min 51s, sys: 345 ms, total: 3min 51s
Wall time: 3min 52s
transition:
[[0.23221903 0.76778097]
 [0.70229989 0.29770011]]

observation:
[[2.81739822e-001 1.43132488e-001 8.48434970e-039 9.75851831e-005
  2.69362672e-015 2.26567133e-001 1.96209466e-052 3.91264554e-003
  3.99838821e-004 1.28228959e-001 5.84694599e-089 2.88371026e-003
  4.14028555e-011 8.80582911e-042 6.35909627e-035 1.38234418e-001
  1.36580291e-003 1.62526402e-074 2.92938439e-044 4.11414990e-009
  1.87721887e-002 4.67200518e-002 8.31615790e-092 2.25223167e-053
  6.94701181e-054 7.94535098e-003 3.77091958e-115]
 [6.45306779e-002 2.28885541e-011 2.11388638e-002 5.09197312e-002
  6.65567850e-002 3.53676378e-028 3.41974735e-002 2.33806094e-002
  7.04417813e-002 4.39068533e-035 2.25940754e-003 5.05942349e-003
  7.26074017e-002 3.71078968e-002 1.14425589e-001 7.88275501e-014
  3.32161677e-002 1.53180173e-003 1.00486193e-001 1.06804872e-001
  1.33136144e-001 1.33386835e-016 1.62753933e-002 2.13686341e-002
  4.51881509e-003 1.88874875e-002 1.14885129e-003]]

initial states:
[[1.00000000e+00 2.47001026e-27]]
#+end_example

* rand res
#+begin_example
27 [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
50000 out of 50000
the model stopped improving at iteration 174
CPU times: user 3min 28s, sys: 216 ms, total: 3min 28s
Wall time: 3min 28s
transition:
[[0.2974586  0.7025414 ]
 [0.76846507 0.23153493]]

observation:
[[6.55124847e-02 5.71952340e-11 2.11330838e-02 5.08030870e-02
  6.65385862e-02 3.93175379e-25 3.41881229e-02 2.32168465e-02
  7.07175312e-02 2.43068346e-26 2.25878976e-03 5.05000573e-03
  7.25875474e-02 3.70977504e-02 1.14394302e-01 4.80742210e-13
  3.31094650e-02 1.53138289e-03 1.00458717e-01 1.06774963e-01
  1.32618810e-01 4.32678209e-12 1.62709432e-02 2.13627913e-02
  4.51757952e-03 1.87086727e-02 1.14853716e-03]
 [2.80742624e-01 1.43181293e-01 2.26272409e-29 2.09981536e-04
  2.64622305e-10 2.26602508e-01 1.24335623e-37 4.08612102e-03
  7.72735123e-05 1.28272682e-01 2.02411595e-67 2.89348203e-03
  1.59773171e-09 3.42954114e-32 6.43777215e-29 1.38281553e-01
  1.47305209e-03 1.26206542e-55 7.16990137e-37 7.74877804e-07
  1.93046624e-02 4.67359820e-02 2.40155627e-72 2.12006626e-37
  1.26711428e-45 8.13801016e-03 1.70507529e-93]]

initial states:
[[0.47197308 0.52802692]]
#+end_example

* Questions
 - "For example, the DP solution must have valid state transitions" ? How can transitions be invalid ?
 - Where does the initial states distribution matrix come from ?
 - Does $N \times M$ means $N$ rows $M$ columns or $N$ columns $M$ rows

